BaseML安装
pip install baseml 或 pip install BaseML
可以在命令行输入BaseML查看安装的路径，在安装路径内，可以查看提供的更多demo案例。
库文件源代码可以从PyPi下载，选择tar.gz格式下载，可用常见解压软件查看源码。

BaseML功能详解
我们的传统机器学习（Mechine Learning）有很多算法，但总的来说，可以分为三大类：分类、回归和聚类。BaseML和sklearn不同之处，也就体现于此，sklearn尽管在拟合、预测等函数上对各模块做了统一，但并没有明确指出这样的三大类划分方式。这三类也有着特有的数据输入格式。
文档涉及的部分代码见XEdu帮助文档配套项目集：https://www.openinnolab.org.cn/pjlab/project?id=64f54348e71e656a521b0cb5&sc=645caab8a8efa334b3f0eb24#public
机器学习的基本流程
机器学习实际上分为两个阶段，首先是模型训练过程，即“学习”；然后是模型推理过程，即“应用”。典型的机器学习流程可以分为数据准备、模型搭建、模型训练与评估、模型应用等环节（如下图）。
1.数据准备
数据是描述客观事物或现象的符号记录，可以是数字、文字、图像、声音等形式。机器学习需要很多数据，我们称之为“数据集”。要训练怎样的模型，就要准备怎样的数据。例如要训练温度转换的模型，就要准备很多条类似“摄氏温度和华氏温度对应表”的数据。
2.模型搭建
搭建机器学习的模型，核心工作是实现一个具有特定功能的算法。实现机器学习的算法需要编写程序，难度较大。但好消息是Python有多个机器学习的库，这些库中内置了各种优秀的算法，只要根据需要选择合适的算法，就可以直接完成模型的搭建。
3.模型训练与评估
对于训练好的模型，需要评估一下其推理能力，类似人学习了某个课程后，还要做点单元小测试，看看掌握了多少。对回归任务来说，简单好用的评估指标之一是R平方值，对分类任务来说，一般选择准确率。通过比对推断结果与实际标注结果的差异，可以计算出评估指标。如果推理效果不好，要重新检查数据和模型，再次训练。
4.模型应用
当训练出来的模型的评估表现不错，那就可以保存模型。保存出来的模型文件，可以导入使用或供其他程序使用。其实模型应用环节和传统编程就差别不大了，只要输入一组新数据，就能输出预测结果。
机器学习典型算法一览表
点击对应的回归或分类，可连接至该算法更详细的说明文档。
算法名称
适合任务
典型任务
算法解释
常用参数及其默认值
线性回归（LinearRegression）
回归
适用于预测房价、预测销售额、贷款额度等。
线性回归（Linear Regression）线性回归算法的核心思想是找到一条直线，使得这条直线能够最好地代表和预测数据。通常适用于连续值的预测，例如房价、贷款额度等。线性回归就像用直尺在散点图上画一条尽可能穿过所有点的直线，这条直线就能帮我们预测未来的值。
fit_intercept=True, positive=False
多项式回归算法（Polynomial）
回归
适用于预测房价、预测销售额、贷款额度等。
就像是在一条直线上增加更多的弯曲，使得这条线可以更好地贴合数据点。就像用橡皮筋在散点图上拉出一个曲面，这个曲面就能更好地帮助我们预测未来的值。
degree=2, interaction_only=False, include_bias=True, order='C'
最近邻分类（KNN, K-Nearest Neighbors）
分类
识别数字、判断邮件是否为垃圾邮件、图像识别等。
最近邻分类算法核心思想是“近朱者赤”。如果要分析一个新数据点的类别，我们会寻找离它最近的K个邻居，哪类邻居多，就认为新数据点也属于该类。适用于数据集较小等情况，分类结果直观。假设你在一个聚会上不认识任何人，你可能会找和你最相似的人群加入。KNN算法也是这样工作的，它通过查找最相似（最近邻）的数据点来进行分类。
n_neighbors=5, p=2（距离计算方式）
支持向量机（SVM, Support Vector Machine）
分类/回归
文本分类、图像识别、股票市场分析等。
支持向量机算法在一个高次元空间来思考问题，尤其适合处理多特征、非线性和少样本的学习问题。此外，它能够很好地适应干扰数据和异常值带来的模型误差。可用于分类和回归。此处使用支持向量机（SVM）完成分类任务。想象你有两种颜色的球分布在桌子上，SVM就是用一根棍子（在复杂情况下是一张弯曲的板）尽可能分开两种颜色的球。
kernel='rbf', gamma='scale', tol=0.001, C=1.0
决策树算法（CART）
分类/回归
适用于客户分级、疾病诊断等。
决策树算法将数据看作树的若干片叶子。在每一个树杈位置，决策树都根据特征的不同而划分，将不同的叶子分在不同的枝干上，算法根据最优划分方法，将误差降到最低。该算法解释性强，在解决各种问题时都有良好表现。此处使用决策树分类（CART）完成分类任务。想象你在做一个选择（比如选择餐馆），你可能会根据一系列问题（离家近不近？价格怎么样？）来决定。决策树算法就是通过一系列问题来达到决策的过程。
criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None
随机森林算法（Random Forest）
分类/回归
信用评分、医疗分析、股票市场行为等。
随机森林算法是一种基于集成学习的算法，通过构建多棵决策树并将它们的预测结果进行集成，从而降低风险。它能够处理多特征数据，并自动选择最相关特征，从而提升模型准确率。如果你问很多朋友一个问题，并根据他们的回答来做决定，那么你就用了随机森林的思想。它建立了很多个决策树，并综合它们的意见来做出最终的决策。
n_estimators=100, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, bootstrap=True, oob_score=False, warm_start=False
自适应增强算法（AdaBoost）
分类/回归
人脸识别、客户流失预测、分类任务等。
自适应增强算法（Adaptive Boosting，AdaBoost）是一种迭代算法，需要经历多个阶段，在每个阶段都增加一个新的智能体帮助判断，直到达到足够小的错误率。这种算法在各领域都表现出超凡的能力。想象一个团队里有很多成员，每个人在第一次做决策时可能不是很准确。但随着时间的推移，团队成员学习如何根据过去的错误来改进，使得整个团队的决策越来越好。
n_estimators=50, learning_rate=1.0, loss='linear'
多层感知机算法（MLP）
分类/回归
适用于语音识别、手写识别、自然语言处理等。
多层感知机算法是一种深度学习算法。它通过模拟大脑的神经元系统，将信号通过突触传递到与之相关的神经元中，如果传递正确，这样的传递就会被强化，从而逐渐构成模型。它可以自动学习到输入特征之间非常复杂的关系。但是，它的训练时间可能会较长，且依赖大量训练数据。想象你在通过多层不同的筛子来过滤沙子，每层筛子的网眼大小不同。沙子在通过每层筛子时都会被进一步细分。多层感知机就是通过多层处理（神经网络层）来从数据中学。
hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000
……
……
……
……
……
代码详解
核心代码：
python
from BaseML import Regression as reg # 从库文件中导入回归任务模块
model = reg('LinearRegression') # 实例化线性回归模型
model.set_para(fit_intercept=True) # 设定模型参数
model.load_tab_data( './data_train.csv') # 载入训练数据
model.train() # 训练模型
model.valid('./data_val.csv',metrics='r2') # 载入验证数据并验证
model.save('mymodel. pkl') # 保存模型供应用
其中设定模型参数非必要，各参数都有默认值，具体见上表。
1. 导入包与搭建模型
库文件的导入只需要一行代码，根据机器学习的任务导入相应的库。“Regression”模块内置了回归任务的常见算法，“Classification”模块内置了分类任务的常见算法，“Cluster”模块则内置了聚类任务的常见算法。
在BaseML中使用不同算法：
第二句代码属于模型搭建，除了实例化模型，选择部分算法如需额外设置参数可添加参数设置的代码（涉及的参数见上文的机器学习典型算法一览表），一般有如下三种搭建形式，下面以搭建多层感知机算法为例进行说明，此算法一般需要设置隐藏层"hidden_layer_sizes"，hidden_layer_sizes":(100,200)表示2层神经元数量为100和200的隐藏层。如下是他的三种搭建形式。
```python
第一种形式
param = {"hidden_layer_sizes":(100,200), }
model = reg("MLP",para=param)
第二种形式
model = reg("MLP")
model.para = {"hidden_layer_sizes":(100,200), "activation":'relu', "solver":'adam'}
第三种形式
model = reg("MLP")
model.set_para(hidden_layer_sizes=(100,200), activation='relu', solver='adam')
```
拓展功能：查看各任务拥有的算法以及类注释
```python
from BaseML import Regression as reg
reg.doc
from BaseML import Classification as cls
cls.doc
from BaseML import Cluster as clt
clt.doc
```
2. 数据载入
BaseML库支持各种形式载入数据。
（1）针对CSV数据
方法1：使用load_tab_data方法直接载入一个CSV文件（对CSV文件有严格格式要求：数据文件每行一条记录，输入数据（特征）列在前，输出数据（目标或标签）列在后，即最后一列为输出数据，其余列为输入数据，且要求数据类型为数值类型并无缺失值）。
model.load_tab_data('data/Height_data_train.csv')
返回值是x_train, y_train, x_val, y_val: 训练集和验证集，如无则返回“None”。
参数说明：
data_path：CSV数据集路径，数据格式要求如下：
train_val_ratio ：训练集与验证集的比例，float类型，默认值为1.0，即默认不划分，全部作为训练集。
shuffle： 是否打乱数据，默认为True。
random_seed：随机数种子，用于复现代码效果。
方法2：使用load_dataset方法载入，需指定文件类型、特征列和标签列，可辅助做特征选择，此方法载入数据更加灵活。
```
载入数据集，并说明特征列和标签列
model.load_dataset('./lenses.csv', type ='csv', x_column = [1,2,3,4],y_column=[5])
```
参数说明：
type表示X和y的输入格式，可选项为‘csv'、‘numpy'、'pandas'、'list'、'txt'。
x_column表示特征列。
y_column表示标签列。
split：是否划分训练集、验证集，默认为True。
shuffle： 是否打乱数据，默认为True。
scale是否对数据进行归一化，默认为False。
show：显示5条数据。默认为True。
（2）针对图片数据
如需载入图像数据，可读取图像数据转换为Numpy数组后，直接从变量载入数据。使用上文介绍过的载入数据更加灵活的load_dataset方法载入即可。
```python
载入数据，并说明特征列和标签列
model.load_dataset(X=train_x, y=train_y,type ='numpy')
```
X表示数据特征，y表示标签。可再设置x_column和y_column参数，不设置则默认指定的X和y的所有列。
其他参数同上文。
辅助工具：BaseML内置的图像处理模型ImageLoader
如需对图片进行处理后再载入，可借助BaseML内置的图像处理模型ImageLoader。
简单使用示例：
以读取ImageNet格式的MNIST数据集为例，进行说明。
```python
from BaseML import IMGLoader
指定数据集路径
train_path = '/data/QX8UBM/mnist_sample/training_set'
test_path = '/data/QX8UBM/mnist_sample/test_set'
初始化图片加载器并载入数据集
img_set = IMGLoader.ImageLoader(train_path, test_path,size=28)
图像数字化处理
X_train, y_train, X_test, y_test = img_set.get_data(method='flatten')
```
```python
载入数据，从变量载入
model.load_dataset(X=X_train, y=y_train,type ='numpy')
```
更多使用示例详见后文。
3. 模型训练
```python
模型训练
model.train()
```
4.模型评估
```python
模型评估
model.valid(metrics='acc')
```
valid方法的返回值有2个，分别是评估指标计算结果和验证集的推理结果。
参数说明：
metrics：评估指标选择，默认为'acc(accuracy)'，还支持precision,recall,f1,auc,r2,mse,mae、Silhouette Score、Calinski-Harabasz Score、Davies-Bouldin Score等。分类任务一般选择'acc(accuracy)'，回归任务可以选择'r2'(R平方值)或'mse'(MSE值)，聚类任务一般选择Silhouette Score（轮廓系数），评估指标的说明详见后文。
path/x,y: 验证集的路径/验证集的特征和验证集的标签，如载入数据时设置了自动划分训练集和验证集，此时可不传入此参数，其他情况下基本需要传入，否则将报错。注：聚类任务只需传入metrics，因为聚类和分类回归不一样，没有类别标签，即y只有预测值，没有真实值，因此聚类任务验证实际是对训练集的效果评价，因此不传入x和y也可直接验证。
如载入的是文本数据且直接使用load_tab_data载入，评估时可直接载入一个数据集格式要求及输入列数量等和训练数据保持高度一致即可的验证集进行模型评估即可。
python
model.valid('data_val.csv',metrics='acc') # 载入验证数据并验证
除了传入验证集的路径，还可在valid方法中传入x验证集的特征和y验证集的标签进行模型评估，此方式更加灵活。
```python
模型评估
model.valid(x=val_x,y=val_y,metrics='acc') 
```
5. 评价指标可视化
python
model.metricplot()
使用前面运行的代码中读取的验证集的特征val_x和验证集的标签val_y进行绘制，如无或想自行传入，可自行设置。
上图是线性回归任务绘制的可视化图，验证集已有的输出y为横坐标，通过模型推理得到的结果ŷ为纵坐标，如果两者构成的坐标点落在灰色虚线上，说明模型完全契合验证数据。而实际构成的点没有落在灰色虚线上，而是围绕黑色虚线分布，两条虚线相差越大，说明模型效果越差。
6. 模型推理
```python
给定一组数据，推理查看效果
y=model.inference([[1,1,1,1]])
```
7. 模型的保存与加载
```python
保存模型
model.save('my_CART_model.pkl')
加载模型
model.load("my_CART_model.pkl")
```
参数为模型保存的路径。
模型保存后可加载模型进行模型测试，参考代码如下：
```python
加载模型
model.load("my_CART_model.pkl")
给定一组数据，推理查看效果
y=model.inference(data)
```
8. 模型应用
模型应用是将训练好的模型部署到实际场景中，例如集成到网站或移动应用中。一般来说，一个训练模型的工具也会自带了推理功能，如在BaseML训练好模型并保存，下次使用时以同样的方式导入BaseML库并载入模型进行推理即可。还有种方式是借助一些通用的模型推理库，如XEdu工具的XEduHub库，支持推理各种工具训练的模型，此类库的安装一般比机器学习开发工具简单很多。也可以借助XEduHub库完成推理和应用，核心代码如下。
python
from XEdu.hub import Workflow as wf
baseml = wf(task='baseml',checkpoint='./model.pkl') # 指定使用的pkl模型
data = [[1, 1, 1, 1]]# 指定测试数据，根据训练模型时使用的数据来定
result= baseml.inference(data=data) # 进行模型推理
print(result)
附录
1. 分类、回归和聚类
如果预测任务是为了将观察值分类到有限的标签集合中，换句话说，就是给观察对象命名，那任务就被称为分类任务。另外，如果任务是为了预测一个连续的目标变量，那就被称为回归任务。
所谓聚类，即根据相似性原则，将具有较高相似度的数据对象划分至同一类簇，将具有较高相异度的数据对象划分至不同类簇。聚类与分类最大的区别在于，聚类过程为无监督过程，即待处理数据对象没有任何先验知识，而分类过程为有监督过程，即存在有先验知识的训练数据集。
2. 常见评估指标
Precision (精确率)：分类任务。用来衡量正类预测的准确性。想象一下，你用网捞鱼，精确率就是你捞上来的所有鱼中真正你想要的鱼的比例。在分类任务中，精确率表示的是被正确预测为正类（如真实的病例、真正的信号）的实例占所有预测为正类的实例的比例。
Recall (召回率)：分类任务。用来衡量模型捕捉正类实例的能力。召回率表示的是正确预测为正类的实例占所有实际正类的实例的比例。
F1 Score (F1分数)：分类任务。平衡精确率和召回率，尤其适用于不平衡数据集。精确率和召回率像是一对矛盾的兄弟，一个高，另一个往往就低。F1分数就是这两个兄弟的和平协议，它找到了两者之间的平衡点。F1分数是精确率和召回率的调和平均数，用于给出单个度量，在两者之间取得平衡。
AUC (曲线下面积)：分类任务。衡量模型区分两个类别（正类和负类）的能力。想象一下你画了一条线分隔好人和坏人，AUC衡量的就是这条线分隔好坏人能力的指标。AUC是接收者操作特性（ROC）曲线下的面积，值越高，表示模型区分正类和负类的能力越强。
R2 (决定系数)：回归任务。衡量模型解释数据变异的能力。这个指标告诉我们模型对现实数据的拟合程度如何。值为1意味着模型完美拟合数据，值为0意味着模型不比随机猜测好。你可以把它看作是评分你的模型对数据了解程度的考试成绩。
MSE (均方误差)：回归任务。衡量模型预测值和实际值差异的平方的平均值。如果你射箭，每次射箭偏离靶心的距离的平方的平均值，就是均方误差。它衡量的是模型预测值与实际值之间差异的平方的平均值。
MAE (平均绝对误差)：回归任务。衡量模型预测值和实际值差异的绝对值的平均值。同样的射箭比喻，每次射箭偏离靶心的距离的平均值，就是平均绝对误差。它是模型预测值与实际值之间差异的绝对值的平均值。
Silhouette Score (轮廓系数)：聚类任务。衡量簇的紧密性和分离度。这个指标像是给每个点打分，看它是不是跟自己组里的点挨得很近，同时跟其他组的点挨得很远。分数从-1到1，分数高说明聚类效果好。
Calinski-Harabasz Score (CH指数)：聚类任务。基于簇内和簇间离散度来评估聚类的质量。这个指标就像评价一个足球队的防守和进攻。防守紧凑表示同一个簇内的点很接近，进攻犀利表示不同簇的点相隔很远。CH指数越高，聚类效果越好。
Davies-Bouldin Score (DB指数)：聚类任务。评估簇的分离度，较低的值表示更好的分离效果。这个指标试图衡量簇内的相似性和簇间的差异。想象你有很多圈朋友，DB指数就像衡量每个圈子里的朋友有多相似，以及不同圈子。
3. 其他算法
贝叶斯分类
贝叶斯分类算法常用于解决不确定问题，如人们普遍认为夜里下雨，第二天早晨草地会湿，实际到了早上草地可能就干了，也许是因为风的因素，解决这类问题往往需要根据人类已有的经验来计算某种状态出现的概率，这种方式叫做贝叶斯推理。 贝叶斯分类算法是基于贝叶斯定理的一种算法，即“简单”地假设每对特征之间相互独立。
贝叶斯定理：P(A|B)表示事件B发生的条件下事件A发生的概率，P(A|B)等于事件A发生的条件下事件B发生的概率乘以事件A发生的概率P(A)，再除以事件B发生的概率P(B)。
```python
实例化模型，模型名称选择NaiveBayes
model=cls('NaiveBayes')
```
k均值
k均值（k-means）算法是一种基于数据间距离迭代求解的聚类算法，通过分析数据之间的距离，发现数据之间的内在联系和相关性，将看似没有关联的事物聚合在一起，并将数据划分为若干个集合，方便为数据打上标签，从而进行后续的分析和处理。k代表划分的集合个数，means代表子集内数据对象的均值。
```python
实例化模型，模型名称选择'KMeans'
model = clt('KMeans')
```
参数n_clusters表示k的值，默认值为5。
谱聚类
谱聚类（spectral clustering）算法主要思想是把所有的数据看做空间中的点，这些点之间可以用边连接起来。将聚类问题转为图分割问题：距离较远（或者相似度较低）的两个点之间的边权重值较低，而距离较近（或者相似度较高）的两个点之间的边权重值较高，将所有数据点组成的图分割成若干个子图，让不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的。
```python
实例化模型，模型名称选择'SpectralClustering',
model = clt('SpectralClustering')
```
参数n_clusters表示子图的数量，默认值为5。
Agglomerative clustering
Agglomerative clutsering 是一种自底而上的层次聚类方法，它能够根据指定的相似度或距离定义计算出类之间的距离。首先将每个样本都视为一个簇，然后开始按一定规则，将相似度高的簇进行合并，直到所有的元素都归为同一类。
```python
实例化模型，模型名称选择'Agglomerative clustering'
model = clt('Agglomerative clustering')
```
参数n_clusters表示聚类的数量，默认值为5。

BaseML项目案例集
探秘BaseML之MLP（多层感知机）
本案例选用了多套教材中的数据集，并都使用MLP算法对数据集进行训练，实现了分类和回归两大任务。
项目地址：https://openinnolab.org.cn/pjlab/project?id=65f69017ace40851ae424258&sc=635638d69ed68060c638f979#public
分类任务实现代码举例
python
from BaseML import Classification as cls # 从库文件中导入分类任务模块
model = cls('MLP') # 实例化MLP模型
model.set_para(hidden_layer_sizes=(10,10)) # 设定模型参数
                                             # 这里的输入和输出层神经元数量是自动识别的
                                             # 只需要设定隐藏层的神经元数量即可
data = model.load_tab_data('data/road-accessibility-status-analysis.csv',train_val_ratio=0.6) # 载入训练数据
print(data)
model.train(lr=0.01,epochs=100) # 训练模型
model.valid(metrics='acc') # 载入验证数据并验证
model.metricplot()
输出如下：
Setting hidden_layer_sizes to (10, 10)
(array([[ 2., 83.],
       [ 1., 80.],
       [ 1., 90.],
       [ 1., 71.],
       [ 1., 87.],
       [ 2., 29.],
       [ 1., 47.]]), array([1., 1., 1., 2., 1., 1., 2.]), array([[ 1., 73.],
       [ 2., 75.],
       [ 2., 48.],
       [ 1., 68.],
       [ 1., 78.]]), array([2., 1., 1., 2., 2.]))
验证准确率为：80.0%
上面的代码通过metrics='acc'，计算了分类任务的准确性，并可以通过metricplot()将结果可视化。
回归任务实现代码举例
python
from BaseML import Regression as reg # 从库文件中导入回归任务模块
model = reg('MLP') # 实例化MLP模型
model.set_para(hidden_layer_sizes=(10,10)) # 设定模型参数
                                             # 这里的输入和输出层神经元数量是自动识别的
                                             # 只需要设定隐藏层的神经元数量即可
data = model.load_tab_data('data/cake-size-to-price-prediction.csv',train_val_ratio=0.6) # 载入训练数据
print(data)
model.train(lr=0.01,epochs=100) # 训练模型
model.valid(metrics='r2') # 载入验证数据并验证
model.metricplot()
输出如下：
Setting hidden_layer_sizes to (10, 10)
(array([[ 9.],
       [ 6.],
       [10.]]), array([69., 40., 77.]), array([[ 8.],
       [12.]]), array([56., 96.]))
验证r2-score为：98.95081251824811%
上面的代码通过metrics='r2'，计算了回归任务的R平方指标的值，并可以通过metricplot()将结果可视化。
基于决策树的道路智能决策
本案例来源于上海科教版《人工智能初步》人教地图56-58页。
数据集来源：上海科教版《人工智能初步》人教地图56-58页。
项目地址：https://www.openinnolab.org.cn/pjlab/project?id=64140719ba932064ea956a3e&sc=635638d69ed68060c638f979#public
项目核心功能
借助决策树算法完成道路智能决策，可通过学习和实验了解决策树的工作原理，掌握决策树分类任务编程的流程。
数据说明：
第0列：序号；
第1列：道路施工状况：(1) 未施工, (2) 施工；
第2列：预计车流量 ；
第3列：分类结果（道路能否通行）：(1) 不可通行, (2) 可通行。
实现步骤：
1）模型训练
```python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
实例化模型，模型名称选则CART（Classification and Regression Trees）
model=cls('CART')
载入数据集，并说明特征列和标签列
model.load_dataset('./道路是否可通行历史数据f.csv', type ='csv', x_column = [1,2],y_column=[3])
模型训练
model.train()
```
2）模型评估
```python
模型评估,使用载入数据时默认拆分出的验证集进行评估
model.valid()
模型评价指标可视化
model.metricplot()
```
3）模型保存
```python
保存模型
model.save('my_CART_model.pkl')
```
4）模型推理
```python
使用载入功能，复现效果
m=cls('CART')
m.load('my_CART_model.pkl') # 模型保存路径
y=m.inference([[2,  10]]) # 2代表施工中，10代表预计车流量为10
print(y)
print(label[y[0]-1])
```
用多层感知机算法实现手写体数字分类
本案例来源于《人工智能初步》广东教育出版社版75-80页。
项目地址：https://openinnolab.org.cn/pjlab/project?id=6440e64606618727bee5c1ce&backpath=/pjlab/projects/list#public
项目核心功能：
阿拉伯数字的字形信息量很小,不同数字写法字形相差又不大，使得准确区分某些数字相当困难。本项目解决的核心问题是如何利用计算机自动识别人手写在纸张上的阿拉伯数字。使用的数据集MNIST数据集包含 0~9 共10种数字的手写图片，每种数字有7000张图片，采集自不同书写风格的真实手写图片，整个数据集一共70000张图片。70000张手写数字图片使用train_test_split方法划分为60000张训练集（Training Set）和10000张测试集（Test Set）。项目核心功能是使用BaseML库搭建多层感知机实现手写数字识别。
实现步骤：
首先需对MNIST数据集进行图像数字化处理，使用BaseML自带的IMGLoader库。
```python
from BaseML import IMGLoader
指定数据集路径
train_path = '/data/QX8UBM/mnist_sample/training_set'
test_path = '/data/QX8UBM/mnist_sample/test_set'
初始化图片加载器并载入数据集
img_set = IMGLoader.ImageLoader(train_path, test_path,size=28)
图像数字化处理
X_train, y_train, X_test, y_test = img_set.get_data(method='flatten')
```
1）模型训练
```python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
搭建模型，模型名称选择MLP（Multilayer Perceptron）
model=cls('MLP')
设置参数，hidden_layer_sizes":(100,100)表示2层神经元数量为100的隐藏层
model.para = {"hidden_layer_sizes":(100,100)}
载入数据，从变量载入
model.load_dataset(X=X_train, y=y_train,type ='numpy')
模型训练
model.train()
```
2）模型评估
```python
读取验证数据进行评估
model.valid(x=X_val, y=y_val,metrics='acc')
评价指标可视化
model.metricplot(X_val,y_val)
```
3）模型保存
```python
保存模型
model.save('checkpoints/mymodel.pkl')
```
4）模型推理
```python
给定一张图片，推理查看效果
img = '/data/QX8UBM/mnist_sample/test_set/0/0.jpg' # 指定一张图片
img_cast = img_set.pre_process(img)
data = img_set.get_feature(img_cast,method = 'flatten')
print(data)
y = model.inference(data) #图片推理
print(y)
输出结果
label=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
print(label[y[0]])
```
用k近邻为参观者推荐场馆
本案例来源于华师大出版社《人工智能初步》56-57页。
项目地址：https://www.openinnolab.org.cn/pjlab/project?id=6417d0477c99492cf1aa8ba6&sc=635638d69ed68060c638f979#public
项目核心功能：
使用BaseML来实现k近邻（knn）分类算法，为旅行者们推荐最适合他们的场馆。在项目实践中了解k近邻的工作原理，掌握使用BaseML进行k近邻分类的方法。
数据集来源：华师大出版社《人工智能初步》38页。
实现步骤：
首先导入库并进行文本特征数字化。
```python
导入需要的各类库，numpy和pandas用来读入数据和处理数据，BaseML是主要的算法库
import numpy as np
import pandas as pd
from BaseML import Classification as cls
构建字典键值对
yesno_dict = {'是':1,'否':0}
number_dict = {'多':1,'少':0}
weather_dict = {'雨':-1, '阴':0, '晴':1}
采用map进行值的映射
df['首次参观'] = df['首次参观'].map(yesno_dict)
df['参观人数'] = df['参观人数'].map(number_dict)
df['天气'] = df['天气'].map(weather_dict)
df['专业人士'] = df['专业人士'].map(yesno_dict)
```
1）模型训练
```python
实例化模型，KNN默认值为k=5
model=cls('KNN')
载入数据集，并说明特征列和标签列
model.load_dataset(X = df, y = df, type ='pandas', x_column = [1,2,3,4],y_column=[5])
开始训练
model.train()
```
2）模型评估
```python
模型评估,使用载入数据时默认拆分出的验证集进行评估
model.valid()
模型评价指标可视化
model.metricplot()
```
根据可视化生成的图例可以清晰呈现哪些类别预测错误以及预测的结果。
如上图，正确答案是类别0，全部预测正确；
而正确答案是类别1时有一半预测结果为2，一半预测正确，另一半预测错误；
正确答案是类别2的则全部预测错误。
3）模型推理
```python
给定一组数据，查看模型推理结果
test_data = [[0,1,0,1]]
test_y = model.inference(test_data)
print(test_y)
print(loc.inverse_transform(test_y))
```
拓展-修改k值进行训练：
```python
使用k = 3进行训练
model1=cls('KNN')
model1.para = {"n_neighbors":3}
model1.load_dataset(X = df, y = df, type ='pandas', x_column = [1,2,3,4],y_column=[5])
model1.train()
```
用线性回归预测蛋糕价格
本案例来源于人教地图版《人工智能初步》39-41页。
项目地址：https://openinnolab.org.cn/pjlab/project?id=64141e08cb63f030543bffff&backpath=/pjlab/projects/list#public
项目核心功能：
使用线性回归预测蛋糕价格，案例场景贴近生活，可通过学习和实验了解线性回归的工作原理，掌握使用BaseML中的线性回归进行预测的方法。
数据集来源：人教地图版《人工智能初步》39-41页。
实现步骤：
1）模型训练
```python
导入需要的各类库，numpy和pandas用来读入数据和处理数据，BaseML是主要的算法库
import numpy as np
import pandas as pd
from BaseML import Regression as reg
实例化模型
model = reg('LinearRegression')
载入训练数据
model.load_tab_data( '蛋糕尺寸与价格.csv') 
开始训练
model.train()
```
2）模型评估
```python
计算R值进行评估
model.valid('蛋糕尺寸与价格.csv',metrics='r2')
```
3）模型保存
```python
模型保存
model.save('mymodel.pkl')
```
4）模型应用
```python
指定数据
df = pd.read_csv("蛋糕尺寸与价格.csv")
输出模型对于数据的预测结果
result = model.inference(df.values[:,0].reshape(-1,1))
可视化线性回归
import matplotlib.pyplot as plt
画真实的点
plt.scatter(df['蛋糕尺寸/英寸'], df['价格/元'], color = 'blue')
画拟合的直线
plt.plot(df.values[:,0].reshape(-1,1), result, color = 'red', linewidth = 4)
plt.xlabel('size')
plt.ylabel('value')
plt.show()
```
用k均值实现城市聚类分析
本案例来源于人民教育出版社《人工智能初步》（中国地图出版社）56-59页。
项目地址：https://openinnolab.org.cn/pjlab/project?id=6440ce55d73dd91bcbcbb934&backpath=/pjedu/userprofile?slideKey=project#public
项目核心功能：
使用BaseML中的Cluster模块进行聚类，使用matplotlib库对聚类结果进行可视化。该项目可根据同学所在位置，解决聚集点设定问题。可通过学习和实验了解KMeans的工作原理，掌握使用BaseML进行k均值（KMeans）聚类的方法。
数据集来源：自定义数据集。
实现步骤：
首先完成数据读取。
```python
import pandas as pd
观察数据情况
df = pd.read_csv("2016地区GDP.csv")
```
1）模型训练
```python
实例化模型
model = clt('Kmeans')
model.set_para(N_CLUSTERS=5) 
指定数据集，需要显式指定类型. show可以显示前5条数据，scale表示要进行归一化。数量级相差大的特征需要进行归一化。
model.load_dataset(X = df, type='pandas', x_column=[1,2], shuffle=True,scale=True)
开始训练
model.train()
模型保存
model.save('mymodel.pkl')
```
2）模型推理
```python
进行推理
result = model.inference()
print(result)
```
```python
输出最终的城市聚类文字结果
for index, row in df.iterrows():
    print('{0}属于第{1}个城市集群'.format(row['地区'],result[index])) # 输出每一行
```
可视化聚类结果的代码：
```python
可视化最终的城市集群结果
import matplotlib.pyplot as plt
画出不同颜色的城市集群点
plt.scatter(df.iloc[:, 1], df.iloc[:, 2], c=result, s=50, cmap='viridis')
画出聚类中心
centers = model.reverse_scale(model.model.cluster_centers_)
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5)
标出聚类序号
for i in range(model.model.cluster_centers_.shape[0]):
    plt.text(centers[:, 0][i],y=centers[:, 1][i],s=i, 
             fontdict=dict(color='red',size=10),
             bbox=dict(facecolor='yellow',alpha=0.5),
            zorder=0)
```

快速体验BaseML
简介
BaseML库提供了众多机器学习训练方法，可以快速训练和应用模型。
安装
pip install baseml或pip install BaseML
库文件源代码可以从PyPi下载，选择tar.gz格式下载，可用常见解压软件查看源码。
体验
可以在命令行输入BaseML查看安装的路径，在安装路径内，可以查看提供的更多demo案例。
下面我们以用“用KNN对鸢尾花Iris数据集进行分类”案例为示例，体验用BaseML做第一个机器学习项目！
认识鸢尾花数据集：
鸢尾属植物有三个品种，分别是山鸢尾(setosa)、变色鸢尾(versicolor)、维吉尼亚鸢尾(virginica)。这些种类之间差别不大，但是不同种类在花瓣和花萼的形状上有所区别。鸢尾花数据集（iris.csv）中包括150条不同鸢尾花的花萼长度、花萼宽度、花瓣长度、花瓣宽度数据。下面使用的是已经完成拆分的数据，iris_training.csv训练数据集，120条样本数据；iris_test.csv测试数据集，30条数据，可借助BaseDT库快速完成数据集拆分。
训练
0. 引入包
```python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
```
1. 实例化模型
```python
实例化模型
model = cls('KNN')
```
2. 载入数据
```python
指定数据集
model.load_tab_data('datasets/iris_training.csv')
```
3. 模型训练
```python
模型训练
model.train()
```
4. 模型评估
```python
模型评估
model.valid('datasets/iris_test.csv',metrics='acc')
评价指标可视化
model.metricplot()
```
5. 模型保存
```python
模型保存
model.save('checkpoints/baseml_model/knn_iris.pkl')
```
参数为模型保存的路径，.pkl文件格式可以理解为将python中的数组、列表等持久化地存储在硬盘上的一种方式。
推理与应用
使用现有模型直接推理
对一组数据直接推理。
python
model = cls('KNN')
model.load('checkpoints/baseml_model/knn_iris.pkl')
y=model.inference([[5.9, 3.0, 4.2, 1.5]])
输出结果数据类型为array的一维数组。
可以在此基础上完成一个建议系统，输入鸢尾花的花萼长度、花萼宽度、花瓣长度、花瓣宽度，输出该鸢尾花所属的类别。
```python
from BaseML import Classification as cls
model = cls('KNN')
model.load('checkpoints/baseml_model/knn_iris.pkl')
sepal_length = eval(input('花萼长度为(cm): '))
sepal_width = eval(input('花萼宽度为(cm): '))
petal_length = eval(input('花瓣长度为(cm): '))
petal_width = eval(input('花瓣宽度为(cm): '))
构建测试数据
data = [[sepal_length,sepal_width,petal_length,petal_width]]
用上面训练好的模型来做推理
result = model.inference(data)
print("该鸢尾花属于第{0}类".format(result))
```
快速体验
体验BaseML的最快速方式是通过OpenInnoLab平台。
OpenInnoLab平台为上海人工智能实验室推出的青少年AI学习平台，满足青少年的AI学习和创作需求，支持在线编程。在“项目”中查看更多，查找“BaseML”即可找到所有BaseML相关的体验项目。
AI项目工坊：https://www.openinnolab.org.cn/pjlab/projects/list?backpath=/pjlab/ai/projects
（用Chrome浏览器打开效果最佳）
更多案例详见下文。

BaseML辅助工具
内置图像处理模型ImageLoader
ImageLoader是BaseML内置的图片处理模块，用于进行图像数字化处理，读取图片并提取其中的图像特征，如HOG特征和LBP特征，用以进行后续的机器学习任务。
其处理流程源码如下：
```Python
class ImageLoader(object):
    # BaseML中的图像导入处理模块
    def init(self, training_set_path, testing_set_path, label2id={}, size=128):
        """ImageLoader初始化函数
        Args:
            training_set_path (str): 图片训练集路径.
            testing_set_path (str): 图片测试集路径.
            label2id (dict, optional): 自定义的标签id字典. Defaults to {}.
            size (int, optional): 图像被resize的大小,尽量不要改size,否则使用lbp或者hog可能会出错,
            但是如果原始图像过小,可以调整size . Defaults to 128.
        """
        super(ImageLoader, self).init()
        self.X_train = []
        self.y_train = []
        self.X_test = []
        self.y_test = []
        # ImageNet格式的数据集才能被load
        self.training_set_path = training_set_path
        self.testing_set_path = testing_set_path
        self.label2id = label2id
        self.size = size
    # 读取单张图片，进行预处理
    def pre_process(self, img_path):
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # 转为灰度图
        img = cv2.resize(img, (self.size, self.size))
        img.astype(np.uint8)
        return img
    def get_label2id(self):
        # 如果为空，自己读取training_set中所有的类别，并且进行编号
        if self.label2id == {}:
            _id = 0
            for label in os.listdir(self.training_set_path):
                self.label2id[label] = _id
                _id += 1
        return self.label2id
    def get_label_by_id(self, value):
        return [k for k, v in self.label2id.items() if v == value]
    # 提取hog描述符
    def get_hog_descriptor(self, img):
        # 采用默认值设置
        window_Size = (128, 128)  # setting the window size
        block_Size = (32, 32)  # setting the block size
        block_Stride = (16, 16)  # setting the block stride
        cell_Size = (32, 32)  # setting the cell size
        no_bins = 9  # setting the number of bins
        deriv_Aperture = 1
        Sigma = -1.  # setting the value of sigma
        histogramNormType = 0
        L2HysThreshold = 0.2
        gamma = 1  # setting the value of gamma
        no_levels = 64
        signed_Gradients = True
        # running Hog descriptor
        hog = cv2.HOGDescriptor(window_Size, block_Size, block_Stride,
                                cell_Size, no_bins, deriv_Aperture, Sigma,
                                histogramNormType, L2HysThreshold, gamma, no_levels,
                                signed_Gradients)
        return hog.compute(img).T
    # 　提取lbp描述符
    def get_lbp_descriptor(self, img):
        hist_size = 256
        lbp_radius = 1
        lbp_point = 8
        # 使用LBP方法提取图像的纹理特征.
        lbp = skif.local_binary_pattern(img, lbp_point, lbp_radius, 'default')
        # 统计图像的直方图
        max_bins = int(lbp.max() + 1)
        # hist size:256
        hist, _ = np.histogram(
            lbp, normed=True, bins=max_bins, range=(0, max_bins))
        return hist
    # 获取图像特征
    def get_feature(self, img, method):  # 获取一张图片的描述子
        if method == 'hog':
            return self.get_hog_descriptor(img)
        elif method == 'lbp':
            # 返回是一维的，长度256的向量
            return self.get_lbp_descriptor(img)
        elif method == 'flatten':
            # 转成灰度图后直接展平
            return np.array(img).flatten().reshape(1, -1)
    # 构建训练集和测试集
    def get_data(self, method='hog'):
        # 如果为空，自己读取training_set中所有的类别，并且进行编号
        if self.label2id == {}:
            _id = 0
            for label in os.listdir(self.training_set_path):
                self.label2id[label] = _id
                _id += 1
        # 读取训练集中的图片，并且进行处理
        for train_label in os.listdir(self.training_set_path):
            for image in os.listdir(os.path.join(self.training_set_path, train_label)):
                image_url = os.path.join(
                    self.training_set_path, train_label, image)
                img_processed = self.pre_process(image_url)
                img_feature = self.get_feature(img_processed, method)
                self.X_train.append(img_feature)  # 转置后是一行的
                self.y_train.append(self.label2id[train_label])
        # 读取测试集中的图片，进行处理
        for test_label in os.listdir(self.testing_set_path):
            for image in os.listdir(os.path.join(self.testing_set_path, test_label)):
                image_url = os.path.join(
                    self.testing_set_path, test_label, image)
                img_processed = self.pre_process(image_url)
                img_feature = self.get_feature(img_processed, method)
                self.X_test.append(img_feature)
                self.y_test.append(self.label2id[test_label])
        # Convert train and test data to numpy arrays
        self.X_train = np.array(self.X_train)
        self.X_train = self.X_train.reshape(
            (self.X_train.shape[0], -1))  # 转成二维数组
        self.y_train = np.array(self.y_train)
        self.X_test = np.array(self.X_test)
        self.X_test = self.X_test.reshape((self.X_test.shape[0], -1))  # 转成二维数组
        self.y_test = np.array(self.y_test)
        return self.X_train, self.y_train, self.X_test, self.y_test
```
使用此模块，可在BaseML载入数据前，对图片进行快速批量处理后再载入，且能够完成单张图片的HOG特征提取（还可以更换为其他特征），示例代码如下。
```python
导入BaseML的图像处理模块
from BaseML import IMGLoader
定义一个提取单张图片HOG特征的函数
def read_hog_feature_single(file_path):
    # 创建ImageLoader实例并读取图片
    img_set = IMGLoader.ImageLoader(file_path,file_path,size = 128)
    # 对读取的图片进行预处理
    img = img_set.pre_process(file_path)
    # 提取图片的HOG特征
    feature = img_set.get_feature(img,method = 'hog')
    return feature
指定一张图片
img_path = 'test.jpg'
提取HOG特征
data = read_hog_feature_single(img_path)
打印HOG特征和其形状
print("HOG特征：",data)
print("图像形状：",data.shape)
```
自带可视化工具
在做机器学习项目的过程中，可视化能帮助我们了解模型训练状态，评估模型效果，还能了解数据，辅助了解算法模型，改善模型。
BaseML中提供两种可视化方法：模型可视化及评价指标可视化。模型可视化可以通过测试数据及线条勾勒模型的大致形状，有助于解释和理解模型的内部结构。评价指标可视化显示了模型对于数据的拟合程度，描述了模型的性能，方便用户进行模型选择。使用可视化部分的前提是已经对模型进行初始化并且训练完成，否则可视化部分无法正常使用。
1. 模型可视化
目前该模块只支持4类算法的可视化，分别为Classification中的KNN、SVM，Regression中的LinearRegression，Cluster中的Kmeans。调用方法为model.plot()。
2. 评价指标可视化
目前该模块支持Classification、Regression中的所有算法及Cluster中的Kmeans算法，其他算法不支持。调用方法为model.metricplot()。
3. 可视化调用限制
快速体验训练过程可视化全流程！
0. 引入包
```Python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
```
1. 实例化模型
```Python
实例化模型，模型名称选择KNN（K Nearest Neighbours）
model=cls('KNN')
```
2. 载入数据
```Python
载入数据集，并说明特征列和标签列
model.load_dataset('./lenses.csv', type ='csv', x_column = [1,2,3,4],y_column=[5])
```
3. 模型训练
```Python
模型训练
model.train()
```
4. 模型可视化
```Python
模型可视化
model.plot()
```
5. 评价指标可视化
```Python
评价指标可视化
model.metricplot()
```
快速体验推理过程可视化！
0. 引入包
```Python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
```
1. 实例化模型
```Python
实例化模型，模型名称选择KNN（K Nearest Neighbours）
model=cls('KNN')
```
2. 加载模型参数
```Python
加载保存的模型参数
model.load('mymodel.pkl')
```
3. 载入数据
```Python
载入数据集，并说明特征列和标签列
model.load_dataset('./lenses.csv', type ='csv', x_column = [1,2,3,4],y_column=[5])
```
4. 模型推理
```Python
模型推理
model.inference()
```
5. 模型可视化
```Python
模型可视化
model.plot()
```
6. 评价指标可视化
```Python
评价指标可视化
model.metricplot()
```
实际上，训练过程可视化使用的数据与推理过程可视化使用的数据是相同的，均为数据集经过划分后的测试集（model.x_test）。
其他数据可视化
0. 引入包
```Python
导入库，从BaseML导入分类模块
from BaseML import Classification as cls
```
1. 实例化模型
```Python
实例化模型，模型名称选择KNN（K Nearest Neighbours）
model=cls('KNN')
```
2. 加载模型参数
```Python
加载保存的模型参数
model.load('mymodel.pkl')
```
3. 模型推理
```Python
模型推理
test_data = [[0.2,0.4,3.2,5.6],
[2.3,1.8,0.4,2.3]]
model.inference(test_data)
```
4. 模型可视化
```Python
模型可视化
test_true_data = [[0],
[1]]
model.plot(X=test_data, y_true=test_true_data)
```
5. 评价指标可视化
```Python
评价指标可视化, 如果要使用其他数据进行测试，必须先加载之前的数据集
model.load_dataset('./lenses.csv', type ='csv', x_column = [1,2,3,4],y_column=[5])
model.metricplot(X=test_data, y_true=test_true_data)
```

