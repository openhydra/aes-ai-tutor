XEdu的常见错误
令人困扰的错误
对于AI的初学者来说，并不像极客那样熟练掌握代码，或者热衷于解决一大堆的报错，每每遇到红色的输出就发慌。
其实我们也深受其害，有时候一个不经意的小错误，都可能造成数十行的报错提示，解决起来要花不少精力。因此，我们贴心的在XEdu底层开发时设计了错误检查的功能，把初学者常犯的错误用我们自己设计的错误提示体系来解释，希望能够让用户得到更精简且易懂的解释。当然，这里仅检查初学者常犯的错误，并不保证全面。
例如上面的错误，给出了提示Error Code: -103. No such file or directory: body.jpg.，虽然提示是英文的，但是不难看出，其实就是缺少对应的推理图片，可能是图片名称输错了，或者是图片不在对应的路径下，也可能是图片的后缀名不一致等等。当然，如果还是不清楚，可以拿着103这个编号（下文称为错误码），到下面的错误提示查询目录进行查询，可以看到中文的解释。
有了这样清晰明了的错误提示，再学习AI就不会那么心慌了。
错误提示设计理念
为了能够形成一套有效的错误检查语义体系，我们参考了经典的错误提示设计方案，定义了基本错误反馈。错误描述用英文（考虑到国际化）描述，同时输出错误码。为方便用户查找对应中文含义，可以在此页面Crtl+F调出网页搜索功能，输入错误吗，如“101”，就可以快速跳转到对应的错误释义。代码和目录编号一致，“1.1”的错误代码为“101”。
错误码格式为三段式：错误码+错误现象+原因阐述或解决方案。其中第三段不一定有保证完全匹配。
标准错误输出信息：Error Code: -编号,错误英文提示
示例：Error Code: -101, No such dataset file:XX/XXX/XXX/
错误提示查询目录
1.文件路径错误
1.1 数据集的路径错误
不存在的目录，检查路径是否拼写正确。
英文提示设计：No such dataset directory:XX/XXX/XXX/
- Error Code: -101. No such dataset directory: xxx
1.2 权重文件的路径错误
不存在的权重文件，检查路径是否拼写正确。
英文提示设计：No such checkpoint file:XX/XXX/XXX.pth
- Error Code: -102. No such checkpoint file: xxx
1.3 要推理文件的路径错误
不存在的推理文件，检查路径是否拼写正确。
英文提示设计：No such file:XX/XXX/XXX.jpg
- Error Code: -103. No such file or directory: xxx
2.文件类型错误
2.1 数据集的类型错误
只能是目录，而且目录文件要符合要求。
如果是imagenet：需要检查文件夹名称+txt名称，如果不存在，给出下载地址。指定的图片类别数量必须和数据集一致。val.txt行数也与实际图片数量一致。
如果是coco，类似检查。
英文提示设计：Dateset file type error
case1：传入参数类型不是字符串
- Error Code - 201. Dataset file type error, which should be <class 'str'> instead of <class 'int'>
case 2：数据集路径存在，且为字符串，但其中文件缺失
- Error Code - 201. Dataset file type error. No such file: '../dataset/cls/hand_gray/classes.txt'
case 3：验证集图片数和val.txt中不一致
- Error Code - 201. Dataset file type error. The number of val set images does not match that in val.txt.
case 4: 数据集中图片损坏
图片类型为gif的，也属于损坏。
- Error Code -201. The image file ../../dataset/xx.jpg is damaged.
2.2 权重文件的类型错误
这里要注意区分权重文件的格式，这里要求选择后缀为pth的文件。
英文提示设计：Checkpoint file type error
- Error Code: -202. Checkpoint file type error: xxx
2.3 要推理文件的类型错误
要求是图片类型的文件，如jpg、png、bmp等受支持的文件格式。
英文提示设计：File type error
- Error Code: -203. Inferable file type error: xxx. Ensure your file is in one of the following formats: jpg, png, jpeg, jiff or bmp.
3.参数值错误
参数值就是赋值语句中等于号右边的那个东西，如 a = 3 中的3。
3.1 device设置错误
设备名称目前只能是是cpu和cuda，并且需要以字符串形式输入。
英文提示设计：No such argument.
- Error Code: -301. No such argument: xxx
- Error Code: -301. Your device doesn't support cuda.
3.2 主干网络名称错误
目前只支持‘LeNet’、‘MobileNet’、‘ResNet18’、‘ResNet50’等网络，可以用cls.sota()来查看。
英文提示设计：No such argument
- Error Code: -302. No such argument: xxx. Currently xxx is available.
3.3 validate设置错误
只能是True和False。
英文提示设计：No such argument.
- Error Code: -303. No such argument: xxx
3.4 推理图片格式错误
变量类型必须是str（图片路径）或list[str]（多张图）或numpyarray（点阵图）。（bug目前可视化仅支持路径）
- Error Code: - 304. No such argument: (1, 'asd') which is <class 'tuple'>
4.网络连接相关错误
敬请期待，后续会开发网络相关功能。
5. 参数名称错误
参数名称就是赋值语句中等于号左边的那个东西，如 a = 3 中的a。
5.1 传入的参数名称错误
无此参数，请重新输入。
英文提示设计：No such parameter.
- Error Code: - 501. No such parameter: xxx
6. 代码逻辑错误
6.1 未知图像展示
需要先做图像可视化，再展示。
英文提示设计：No rendered image to show.
- Error Code: - 601. No rendered image to show. Please inference() before show().
6.2 未知数据推理
需要先载入数据，然后再推理。
英文提示设计：No context to inference. 
- Error Code: - 602. No context to inference. Please load_context() before inference().
7. 数据处理错误
7.1 标注数据丢失
对于目标检测任务，缺少了标注的json文件，可能需要检查路径或重新标注。
英文提示设计：Annotation for xxx is missed.
- Error Code: - 701. Annotation for xxx is missed. Please check annotation file(.json) and relabel it.

XEdu的常见函数
XEdu.utils中的函数
在XEdu-python库中，我们封装了一系列数据处理函数，可以帮助你方便地完成AI推理和部署。这些函数被封装在XEdu.utils中，你可以这样引入它们：
python
from XEdu.utils import *
或者具体写明引入的函数
python
from XEdu.utils import softmax, cosine_similarity, get_similarity, visualize similarity
下面对函数展开使用介绍。
softmax
1.函数说明
softmax函数是一个常用的非线性函数，它用于将一个numpy数组映射到0到1之间的数值，同时所有数值之和为1。神经网络最终输出的结果是一串数字，如果想要把数字映射为各类概率，那么使用softmax函数再好不过了。
2.使用示例
```python
from XEdu.utils import *
import numpy as np
data = np.array([[1,2],[3,3]])
output = softmax(data)
print(output)
[[0.2689414213699951, 0.7310585786300049], [0.5, 0.5]]
```
在这个例子中，需要处理两组数据，[1,2]和[3,3]，对于第一组数据，按照softmax算法（一种指数算法）进行映射，得到输出是[0.2689414213699951, 0.7310585786300049]，而第二组数据两个数值相等，得到就是平均分配的[0.5, 0.5]。每一组数据经过处理之后的加和都是一。
3.参数说明
输入参数：
x：numpy array，对数据尺寸没有要求。
输出结果：
list，形状与输入相同，数组映射到0到1之间的数值，同时所有数值之和为1。
4.函数实现揭秘
python
def softmax(x):
    x1 = x - np.max(x, axis = 1, keepdims = True) #减掉最大值防止溢出    
    x1 = np.exp(x1) / np.sum(np.exp(x1), axis = 1, keepdims = True)
    return x1.tolist()
cosine_similarity
1.函数说明
该函数可以比较两个embedding序列的相似度，这里的相似度是以余弦相似度为计算指标的，在高中我们就学习过余弦定理，这里的余弦相似度公式也是类似的，具体计算可以参考这里。
2.使用示例
```python
from XEdu.utils import *
output = cosine_similarity(txt_embeddings1,txt_embeddings2)
print(output)
[[0.86931829 0.94491118 0.94491118]
[0.98270763 0.94491118 0.83152184]]
```
3.参数说明
embeddings_1：一个numpy数组，数据维度为(N, D)，表示N个具有D维的embedding；
embeddings_2：另一个numpy数组，数据维度为(M, D)，表示M个具有D维的embedding；
4.函数实现揭秘
该函数实际是利用了numpy的矩阵乘法运算符@，numpy的矩阵乘法运算符@可以直接实现两个矩阵的点积，从而计算两个embedding序列的余弦相似度。最终输出的结果尺度为(N, M)。
```python
def cosine_similarity(embeddings_1: np.ndarray, embeddings_2: np.ndarray) -> np.ndarray:
    """Compute the pairwise cosine similarities between two embedding arrays.
Args:
    embeddings_1: An array of embeddings of shape (N, D).
    embeddings_2: An array of embeddings of shape (M, D).
Returns:
    An array of shape (N, M) with the pairwise cosine similarities.
"""
for embeddings in [embeddings_1, embeddings_2]:
    if len(embeddings.shape) != 2:
        raise ValueError(
            f"Expected 2-D arrays but got shape {embeddings.shape}."
        )
d1 = embeddings_1.shape[1]
d2 = embeddings_2.shape[1]
if d1 != d2:
    raise ValueError(
        "Expected second dimension of embeddings_1 and embeddings_2 to "
        f"match, but got {d1} and {d2} respectively."
    )
def normalize(embeddings):
    return embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
embeddings_1 = normalize(embeddings_1)
embeddings_2 = normalize(embeddings_2)
return embeddings_1 @ embeddings_2.T
```
5.更多用法
结合XEduHubwf(task='embedding_image')或者wf(task='embedding_text')的任务中，对数据进行embedding操作之后，可以计算不同数据之间的相似度，就可以使用该函数。embedding会在图像嵌入和文本嵌入中用到，具体案例可参见：教程1-7
对两组文本转换出的向量进行相似度比较，可以得到一个比较矩阵，代表每两个字符串之间的相似度，我们可以看到对角线上的词相似度是最高的。下面这个例子将让你有更好的理解：
```python
from XEdu.hub import Workflow as wf # 导入库
from XEdu.utils import *
txt_emb = wf(task='embedding_text')# 实例化模型
txts1 = ['cat','dog'] # 指定文本1
txts2 = ['a cat','a dog','a room','an elephant'] # 指定文本2
txt_embeddings1 = txt_emb.inference(data=txts1) # 获得向量1
txt_embeddings2 = txt_emb.inference(data=txts2) # 获得向量2
print(txt_embeddings1.shape)
(2, 512) 两组文本中的字符串数量无需一致，但都会转换为512个特征
output = cosine_similarity(txt_embeddings1,txt_embeddings2) # 计算向量1和向量2的余弦相似度
print(output)
[[0.94926983 0.86368805 0.7956152  0.8016052 ]
[0.89295036 0.9511493  0.8203819  0.82089627]]
print(softmax(output))
[[0.27485617995262146, 0.25231191515922546, 0.23570789396762848, 0.2371240258216858],
[0.25507545471191406, 0.2703610360622406, 0.23722068965435028, 0.2373427450656891]]
```
图片之间也可以计算相似度，给定的列表中，需要指明各图片的文件所在路径。
python
from XEdu.hub import Workflow as wf # 导入库
from XEdu.utils import *
img_emb = wf(task='embedding_image') # 实例化模型
image_embeddings1 = img_emb.inference(data='demo/cat.png') # 模型推理
image_embeddings2 = img_emb.inference(data='demo/dog.png') # 模型推理
output = cosine_similarity(image_embeddings1,image_embeddings2) # 计算向量1和向量2的余弦相似度
print(output)
print(softmax(output))
get_similarity
1.函数说明
上面的函数cosine_similarity能够计算两个embedding向量的余弦相似度，而get_similarity则提供了更丰富的选择，该函数可以选择相似度的比较算法，可选'cosine', 'euclidean', 'manhattan', 'chebyshev', 'pearson'，默认是'cosine'（method='cosine'）。
2.使用示例
```python
from XEdu.utils import * # 导入库
logits = get_similarity(image_embeddings, txt_embeddings,method='cosine') # 计算余弦相似度
print(logits) # 输出相似度计算结果
[[0.48788464069366455, 0.5121153593063354]]
```
可以看出，使用这个函数是对前面cosine_similarity和softmax的统一封装，这里经历了计算相似度，然后进行归一化的过程。
3.参数说明
输入参数：
embeddings_1：一个numpy数组，数据维度为(N, D)，表示N个具有D维的embedding；
embeddings_2：另一个numpy数组，数据维度为(M, D)，表示M个具有D维的embedding；
method：计算方法，可选'cosine', 'euclidean', 'manhattan', 'chebyshev', 'pearson'，默认是'cosine'（method='cosine'）；
use_softmax：是否进行归一化，默认为True，即进行归一化。
输出结果：
list，形状与输入相同，数组映射到0到1之间的数值，同时所有数值之和为1。
4.函数实现揭秘
该函数实际是利用了numpy的矩阵乘法运算符@，numpy的矩阵乘法运算符@可以直接实现两个矩阵的点积，从而计算两个embedding序列的余弦相似度。最终输出的结果尺度为
输入还可以指定计算方法method，可选'cosine', 'euclidean', 'manhattan', 'chebyshev', 'pearson'，默认是'cosine'（method='cosine'）。
对于相似度计算结果可选择是否进行归一化，默认是进行归一化（use_softmax=True）。
```python
def get_similarity(embeddings_1: np.ndarray, embeddings_2: np.ndarray,method:str='cosine',use_softmax:bool=True) -> np.ndarray:
    """Compute pairwise similarity scores between two arrays of embeddings.
    Args:
        embeddings_1: An array of embeddings of shape (N, D) or (D,).
        embeddings_2: An array of embeddings of shape (M, D) or (D,).
        method: The method used to compute similarity. Options are 'cosine', 'euclidean', 'manhattan', 'chebyshev', 'pearson'. Default is 'cosine'.
        use_softmax: Whether to apply softmax to the similarity scores. Default is True.
Returns:
    An array with the pairwise similarity scores. If both inputs are 2-D,
        the output will be of shape (N, M). If one input is 1-D, the output
        will be of shape (N,) or (M,). If both inputs are 1-D, the output
        will be a scalar.
"""
if embeddings_1.ndim == 1:
    # Convert to 2-D array using x[np.newaxis, :]
    # and remove the extra dimension at the end.
    return get_similarity(
        embeddings_1[np.newaxis, :], embeddings_2
    )[0]
if embeddings_2.ndim == 1:
    # Convert to 2-D array using x[np.newaxis, :]
    # and remove the extra dimension at the end.
    return get_similarity(
        embeddings_1, embeddings_2[np.newaxis, :]
    )[:, 0]
if method == 'cosine':
    similarity =  cosine_similarity(embeddings_1, embeddings_2) * 100
elif method == 'euclidean':
    distance = np.array([[np.linalg.norm(i - j) for j in embeddings_2] for i in embeddings_1]) * 100
    sigma = np.mean(distance)  # Or choose sigma in some other way
    similarity = np.exp(-distance ** 2 / (2 * sigma ** 2)) * 100
elif method == 'pearson':
    similarity = np.array([[np.corrcoef(i, j)[0,1] for j in embeddings_2] for i in embeddings_1]) * 100
else:
    raise ValueError(
        f"Expected method to be cosine,euclidean and pearson but got {method}."
    )
if use_softmax:
    return softmax(similarity)
else:
    return similarity
```
5.更多用法
同样的，结合XEduHubwf(task='embedding_image')或者wf(task='embedding_text')的任务中，对数据进行embedding操作之后，可以计算不同数据之间的相似度，就可以使用该函数。embedding会在图像嵌入和文本嵌入中用到，具体案例可参见：教程1-7
可计算图文、文文、图图的相似度。
cosine_similarity 函数和get_similarity函数的联系
get_similarity 函数实际上是对 cosine_similarity 函数的扩展和泛化。它不仅支持余弦相似度，还支持其他距离测量方法，并提供了可选的 softmax 应用，使其功能更为丰富和灵活。在 get_similarity 中使用 'cosine' 方法时，它会调用 cosine_similarity 函数来计算余弦相似度，同时还有是否进行归一化的处理。因此 cosine_similarity 可以视为 get_similarity 的一个特定实现。
visualize_similarity
1.函数说明
为了能够更加直观地展示相似度计算之后的结果，这里还提供了可视化相似度的方法，调用这个函数，可以将数值映射为不同颜色深度的图像，方便对比。一般配合前面介绍的两个similarity计算函数使用。
2.使用示例
```python
文本-文本比较相似度
from XEdu.hub import Workflow as wf
from XEdu.utils import * 
txt_emb = wf(task='embedding_text')# 实例化模型
txts1 = ['cat','dog','room','elephant'] # 指定文本
txts2 = ['a cat','a dog','a room','an elephant'] # 指定文本
txt_embeddings1 = txt_emb.inference(data=txts1) # 模型推理
txt_embeddings2 = txt_emb.inference(data=txts2) # 模型推理
logits = get_similarity(txt_embeddings1, txt_embeddings2,method='cosine') # 计算余弦相似度
print(logits)
visualize_similarity(logits,txts1,txts2) # 可视化相似度矩阵
```
从图中可以看出，对不同词向量之间进行的对比，对角线上的几个词的相似度是最高的。
3.参数说明
输入参数：
similarity: 前面通过cosine_similarity或get_similarity计算得到的相似度矩阵；
x: List[str]，原始图片或文本的列表；
y: List[str]，原始图片或文本的列表。
figsize:可视化时展示原始图片（如有传入）的尺寸，默认为(10,10)。
输出结果：
一个matplotlib格式的图片。
4.函数实现揭秘
```
def visualize_similarity(similarity, x,y,figsize=(10,10)):
    """Visualize the similarity matrix.
Args:
    similarity: similarity scores matrix. List|ndarray of shape (N, M) or (M, N).
    x: A list of images or texts for each row of the similarity matrix.  List[str]
    y: A list of images or texts for each column of the similarity matrix.
Returns:
    A matplotlib figure object.
"""
# 中文字体，y轴文本/图像
# plt.rcParams['font.sans-serif']=['times'] #用来正常显示中文标签
# plt.rcParams['axes.unicode_minus'] = False #用来正常显示负号
# 图像尺寸
plt.figure(figsize=figsize)
if isinstance(similarity, list):
    similarity = np.array(similarity).T
else:
    similarity = similarity.T
if isinstance(x[0], str) and os.path.exists(x[0]):
    x_im = True
    images = [plt.imread(image,0) for image in x]
else:
    x_im = False
    images = x
if isinstance(y[0], str) and os.path.exists(y[0]):
    y_im = True
    texts = [plt.imread(image,0) for image in y]
else:
    y_im = False
    texts = y
count = len(similarity)
plt.imshow(similarity, vmin=max(0.0, np.min(similarity)), vmax=np.max(similarity), cmap='viridis', interpolation='nearest')
# plt.colorbar()
if x_im and y_im:
    plt.xticks([])
    plt.yticks([])
    for i, image in enumerate(texts):
        plt.imshow(image, extent=( -1.6, -0.6,i + 0.5, i - 0.5,), origin="lower")
    for i, image in enumerate(images):
        plt.imshow(image, extent=(i - 0.5, i + 0.5, 6.5, 5.5), origin="lower")
if y_im and not x_im: # y轴是图片，x轴是文本
    plt.yticks([]) # 去掉y轴刻度
    for i, image in enumerate(texts):
        plt.imshow(image, extent=( -1.6, -0.6,i + 0.5, i - 0.5,), origin="lower")
    plt.tick_params(axis='x', which='both', bottom=False, top=True, labelbottom=False,labeltop=True,pad=0)
    plt.xticks(range(len(images)), images,position=(0,1),)#,fontproperties='SimHei')#, fontsize=18)
if not y_im and x_im: # y轴是文本，x轴是图片
    plt.yticks(range(count), texts)# , fontsize=18)
    plt.xticks([])
    for i, image in enumerate(images):
        plt.imshow(image, extent=(i - 0.5, i + 0.5, -1.6, -0.6), origin="lower")
if not x_im and not y_im: # x轴和y轴都是文本
    plt.yticks(range(count), texts)# , fontsize=18)
    plt.tick_params(axis='x', which='both', bottom=False, top=True, labelbottom=False,labeltop=True,pad=0)
    plt.xticks(range(len(images)), images,position=(0,1),)#,fontproperties='SimHei')#, fontsize=18)
for x in range(similarity.shape[1]):
    for y in range(similarity.shape[0]):
        plt.text(x, y, f"{similarity[y, x]:.4f}", ha="center", va="center")#, size=12)
for side in ["left", "top", "right", "bottom"]:
    plt.gca().spines[side].set_visible(False)
if x_im and y_im:
    plt.xlim([-1.6,len(similarity[1]) - 0.5])
    plt.ylim([-0.5, len(similarity) + 0.5])
elif x_im and not y_im:
    plt.xlim([-0.5, len(similarity[1]) - 0.5])
    plt.ylim([len(similarity)  - 0.5, -1.6])
elif y_im and not x_im:
    plt.ylim([-0.5, len(similarity) - 0.5])
    plt.xlim([-1.6,len(similarity[1]) - 0.5])
plt.title("Similarity Matrix between Features")
plt.show()
return plt
```
5.更多用法
图文相似度比较可视化结果：
图图相似度比较可视化结果：

XEdu的安装和下载
当前在PyPi开源的最新版本号如下：
XEdu-python==0.1.6
MMEdu==0.1.26
BaseML==0.1.3
BaseNN==0.3.0
BaseDT==0.1.3
easy-xedu==0.2.2
BaseDeploy==0.0.4
1.可选的安装方式
为了满足广大中小学师生的需求，XEdu安装方式分为一键安装包安装、pip安装和docker安装。一键安装包版包含MMEdu、BaseML、BaseNN三个模块的基础功能，以及XEduHub、BaseDT、BaseDeploy等工具库，同时内置了一套EasyDL系列工具，分"EasyTrain.bat"、"EasyInference.bat"和"EasyAPI.bat"这三个可视化工具，定期更新。pip安装方式需用户自己分模块安装，各模块更新同步工具开发进度。此外，还推出了docker容器镜像可供选择。
2.初学者安装强推!!!不会让人失望的一键安装包
即刻体验XEdu一键安装包（CPU版本），开始！
下载工具：XEdu一键安装包
下载方式
飞书网盘：XEdu v1.6.7f.exe
下载最新版exe，同时建议准备win10电脑。
第一步：双击运行，将自解压为XEdu文件夹（注意！避免踩坑推荐安装到纯英文路径下）。
第二步：您可以根据个人喜好，选择自己习惯的IDE。
1）使用XEdu自带的Thonny。
Thonny是一款好用的Python轻量级IDE。其最突出的两个特点便是是简洁性和交互性。打开根目录下的"Thonny编辑器.bat"文件快捷方式即可打开Thonny。使用Thonny打开"demo"文件夹中的py文件，如"MMEdu_cls_demo.py"，点击"运行"的"将文件作为脚本运行"即可运行代码，界面如下图所示。
2）使用XEdu自带的Jupyter。
Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。它相对简单，对用户也更加友好，适合初学者。
打开根目录下的"jupyter编辑器.bat"，即自动启动浏览器并显示界面，如下图所示。
使用常用工具栏对代码进行操作，如"运行"，可以在单元格中编写文本或者代码，执行代码的结果也将会在每个单元下方呈现。可以逐个运行单元格，每点击一次，仅运行一个单元格。单元格左侧[*]内的星号变为数字，表示该单元格运行完成。此时可打开"demo"文件夹中的ipynb文件，如"MMEdu_cls_notebook.ipynb"。
3）使用cmd安装用户库。
python中最常用的库管理工具pip，可以使用cmd命令行来运行，打开根目录下的"启动cmd.bat"可以打开cmd命令行界面，如下图所示。
在其中输入想要安装的库文件即可，如"pip install rarfile"。
4）使用其他IDE。
如果您需要使用其他IDE，那么需要您自己配置Python编译器，配置方法如下。
配置环境路径
①打开您的IDE，如PyCharm、Thonny等。
②配置Python编译器，路径为解压路径下的"envs"文件夹下的"interpreter"文件夹中的"python.exe"文件。
执行demo文件
用IDE打开解压路径下的py文件，如"cls_demo.py"，点击"运行"。运行效果应和Thonny一样。
第四步：EasyDL系列体验。
XEdu一键安装包内置了一套EasyDL系列工具，分"EasyTrain.bat"、"EasyInference.bat"、"EasyConvert.bat"和"EasyAPI.bat"这四个可视化工具。
进入EasyDL文件夹，双击即可体验，体验时操作根据界面完成即可。
①双击"EasyTrain.bat"，根据界面完成训练；EasyTrain提供了MMEdu和BaseNN模型的训练流程。
②双击"EasyInference.bat"，根据界面完成推理；
③双击"EasyConvert.bat"，根据界面完成模型转换。
④双击"EasyAPI.bat"，根据界面完成服务部署。
更多EasyDL系列工具详见EasyDL系列无代码工具。
揭秘一键安装包功能
XEdu一键安装版是一个压缩包，解压后即可使用。
XEdu的根目录结构如下：
{.plain}
XEdu
├── checkpoints
├── datasets
├── EasyDL
├── envs
├── utils
├── XEdu示例代码
├── 教学资源
├── bug解决脚本.bat
├── jupyter编辑器.bat
├── IDLE.bat
├── jupyter编辑器.bat
├── PythonTutor代码可视化.bat
├── Thonny编辑器.bat
├── XEdu简介 v1.6.pdf
├── 启动cmd.bat
接下来对每层子目录进行介绍。
checkpoints目录：
存放各个模块的预训练模型的权重文件，分别放在以模块名称命名的文件夹下，如"cls_model"。
datasets目录：
存放为各个模块任务准备的数据集，分别放在以模块名称命名的文件夹下，如"cls"。同时提供了部分数据集的说明文档，如"添加猫狗数据集.txt"，文档提供了数据集下载链接、使用说明、添加数据集流程等。
envs目录：
存放XEdu各模块运行所需的环境和中小学课程常用的库。
utils目录：
存放EasyDL系列功能的源码。
XEdu示例代码目录：
存放各个模块的测试程序，如"cls_demo.py"，并提供了测试图片。测试程序包括py文件和ipynb文件，可支持各种"Python
IDE"和"jupyter notebook"运行，可运行根目录的"Thonny编辑器.bat"和"jupyter编辑器.bat"等后打开测试程序。
EasyDL
存放可视化工具。
几个bat文件
内置特色功能软件。双击打开运行后使用，包括Python编辑器和cmd启动。
XEdu简介 v1.6.pdf：
XEdu一键安装包说明文档。
拓展：windows一键安装包升级GPU版本（如硬件符合要求）
参考视频：B站演示视频 一分钟GPU电脑安装XEdu环境
准备工作：确认是否有cuda
确认您的windows电脑有GPU算力，同时配置了cuda。建议提前检查自己的CUDA和显卡驱动版本，可以在cmd或terminal中，输入nvidia-smi命令检查（我们推荐的CUDA版本是10.1)。
步骤1：卸载CPU版本库
打开一键安装包根目录的启动cmd.bat，输入
pip uninstall torch torchvision mmcv-full -y
步骤2：安装GPU版本的对应库
安装torch：
pip install  torch==1.8.1+cu101  torchvision==0.9.1+cu101  torchaudio==0.8.1 -f   https://download.pytorch.org/whl/torch_stable.html
注：如果安装速度太慢，可以部分选择国内镜像源，指令如下
pip install  torch==1.8.1+cu101  torchvision==0.9.1+cu101  torchaudio==0.8.1 -f   https://download.pytorch.org/whl/torch_stable.html -i https://pypi.douban.com/simple
安装mmcv-full：
建议直接输入：
pip install mmcv-full==1.4.5 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html
如果想要用其他cuda版本或者torch版本，虽然不建议，但你可以在这里找到对应的预编译版本的mmcv-full：https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html
步骤3：确认是否正确启动cuda训练
至此，已完成了MMEdu（GPU版）的升级，可以将train中的device参数赋值为'cuda'，试试速度有没有相较CPU版本有显著提升。
3.学校教学强推!!!OpenHydra服务器部署
缘起：学校教学之困境
因为学校机房的主机可能性能不强，但是又无法采购合适的intel新电脑或者nvidia显卡主机，尽管可以用浦育平台算力缓解燃眉之急，只需要浏览器就可以实现编程。但是受限于学校出口带宽等种种原因，AI教学依然受限，为此我们给出了一个新思路。可以用配置服务器的形式，为学校AI教学采购一款带GPU算力的服务器。有了服务器硬件之后，如何安装python环境，让学生能够像使用浦育平台一样使用校内等本地服务器算力呢？就请出我们的重磅嘉宾：水螅矩阵（OpenHydra） 一款开源的GPU算力分配系统。
开源助力AI教育丨九州未来@2024 GDC主题工作坊圆满举办
项目开源在GitHub ，欢迎有能力的社区公民参与贡献！
OpenHydra的能力
这套系统可以让一台服务器提供满足班级授课的python运行环境，同时内置了XEdu等多种预装环境，以及多套分层AI教学课程。当系统启动后，教师和学生可以登陆网页进行管理和使用。
学生登陆后，将可以启动EasyTrain、JupyterLab、VS Code等多种AI学习环境，使用浏览器即可完成Python程序运行（程序都运行在服务器系统上）。OpenHydra的强大之处在于让不同的学生可以同时使用一台服务器的资源进行计算，而这一切，仅仅基于浏览器就可以实现。
教师可以为系统添加更多的数据集、课程、算力、用户等必要的资源，同时，也可以对资源的分配进行控制。可以配置系统为纯CPU模式，也可以指定每个学生可以拥有的内存空间大小、显存空间大小，以及学生的预装python环境。
官方B站账号：OpenHydra
OpenHydra平台操作指南
 
OpenHydra的安装
最简单的安装教程参见：U盘模式为服务器安装ISO
简单总来来说，安装只有三步：
烧录镜像（下载iso之后，Windows系统可以rufus进行烧录）
ISO镜像下载地址，见U盘模式为服务器安装ISO 。
视频演示见OpenhydraUSB烧制指南 。
 
配置系统（将U盘插入服务器，然后配置安装设置）
视频演示见Openhydra安装教程
等待系统安装完成（系统中间提示重启的时候，需要拔下U盘后手动确认，之后就等待系统安装完成即可）
视频演示见Openhydra安装教程
 
4.使用pip安装
XEdu的MMEdu、BaseML、BaseNN等各模块库均已支持pip安装并会持续迭代。
0.准备工作
强烈推荐你在conda的基础上安装XEdu环境，可以避免很多的版本冲突问题。
1）安装conda
若您已经安装好conda，该步骤可跳过。
下载
可以在官网下载到Anaconda或者Miniconda，conda官网：https://www.anaconda.com/
当然，我们也已经为您挑选好合适的版本，可以直接点此链接下载：miniconda-py38
点击Download开始下载，下载完成后得到exe文件。
安装
双击exe文件即可开始安装（一般下载完成后会自动打开安装界面无需点击exe文件，若没有自动打开安装页面再点击此exe文件）。
打开安装界面后，依次选择Next -> I Agree -> All Users -> Next
-> Next -> Add Anaconda3 to the system PATH environment variable
-> Install -> Next -> Next -> Finish
2）安装python编辑器
若您已经安装好合适的python编辑器，该步骤可跳过。
此处以安装Thonny为例，其他编辑器例如Pycharm，VScode等也支持，用户自行配置好Python编译器即可。
下载
首先打开Thonny官网：https://thonny.org/
右上角选择合适的操作系统点击下载，此处以windows为例
安装
双击exe文件即可开始安装（一般下载完成后会自动打开安装界面无需点击exe文件，若没有自动打开安装页面再点击此exe文件）
打开安装界面后，依次选择Install for me only -> Next -> Next ->
Next -> Next -> Next -> Install -> Finish
运行
在安装好Thonny之后，在第一次运行的时候，会提示选择界面语言和初始设置，选择'Standard'模式即可。
配置Thonny的Python解释器
点击Thonny主界面右下角的Python版本号，可以选择对应的Python解释器，第一次配置点击Configure inter preter，弹出的窗口中，第一个下拉栏选择可选的python3解释器或虚拟环境，
第二个下拉栏找到自己之前安装的anaconda环境中的python解释器位置。点击确认即可使用该python解释器。
1.pip安装MMEdu
1.1 安装MMEdu(CPU版本)
1）Linux安装MMEdu
点击鼠标右键，打开终端。
终端中输入pip install MMEdu即可安装。
{.powershell}
$ pip install MMEdu
注！！！为避免出现版本冲突，建议新建一个conda环境，并在新环境中执行以上命令（注：要求python\<3.9）。
{.powershell}
$ conda create -n your_env_name python=3.8
$ conda activate your_env_name
$ pip install MMEdu
注：请将命令中的"your_env_name"换成你喜欢的名称，如"mmedu"。
2）Windows安装MMEdu
同时按下win+r，输入cmd，回车，打开一个命令行窗口，激活虚拟环境。
在命令行中使用pip安装即可。
{.powershell}
$ pip install MMEdu -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8.0/index.html
注！！！为避免出现版本冲突，建议新建一个conda环境，并在新环境中执行以上命令（注：要求python\<3.9）。
{.powershell}
$ conda create -n your_env_name python=3.8
$ conda activate your_env_name
$ pip install MMEdu -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.8.0/index.html
如使用MMEdu的MMDet模块出现问题，可见后文关于pip安装MMEdu的详细说明。
1.2 安装MMEdu(GPU版本)
B站演示视频：一分钟GPU电脑安装XEdu环境
准备工作：确认是否有cuda
打开命令行，输入nvidia-smi，输出如下：
步骤1：创建一个新的虚拟环境
在准备工作中已完成conda安装，此时可创建一个新的虚拟环境。
conda create -n xedu python=3.8
步骤2：安装torch+101等
在刚才的python环境中，输入下面的指令进行全部库和工具的安装：
pip install torch==1.8.1+cu101 torchvision==0.9.1+cu101 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
pip install mmcv-full==1.4.5 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html
pip install MMEdu basenn baseml basedt basedeploy easy-xedu xedu-python
pip install jupyter lab
如下进行如上命令的具体说明（感兴趣查看，已经运行上面的4行命令如下解释时的命令无需运行）：
安装对应自己cuda版本的pytorch，安装命令可在以下网址中进行查询：https://pytorch.org/get-started/locally/
可以在命令行中使用nvidia-smi指令查询自己的cuda版本，这里只要cuda版本高于10即可。
建议使用下面的指令安装cuda10.1对应的torch1.8.1，安装命令为：
{.powershell}
pip install torch==1.8.1+cu101 torchvision==0.9.1+cu101 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html
其次，安装mmcv-full。
{.powershell}
pip install mmcv-full==1.4.5 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html
如果想要安装其他版本，可以尝试下面的指令：
{.powershell}
pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html
其中 {cu_version} 和 {torch_version}
根据自身需求替换成实际的版本号。
例如想安装和 CUDA 10.1、PyTorch 1.8.0 兼容的
mmcv-full，使用如下替换过的命令
最后安装MMEdu及其他工具。
{.powershell}
pip install MMEdu
pip install jupyter lab
步骤3：确认是否正确启用torch
激活python后，可以运行下面的命令：
import torch
print(torch.__version__)
print(torch.cuda.is_available())
步骤4：确认是否正确启动cuda训练
启动已安装的jupyter lab，使用启动GPU训练的代码，看看是否加速了。
2. pip安装BaseML
pip install baseml 或 pip install BaseML
3. pip安装BaseNN
pip install basenn 或 pip install BaseNN
5.docker容器镜像
首先需要确保您的电脑系统盘（C盘）空间剩余空间超过5GB，实际建议有10GB及以上空间，便于后续训练使用。如果想要调整存储空间位置，可以参考这里修改安装路径，这里修改数据路径，后文安装过程中也有具体叙述。
1.安装Docker软件
这里以Windows11系统（专业版）为例，其他系统可以在网上查找相关教程自行安装Docker，如菜鸟教程。
Windows11系统中，可以先安装Docker Desktop图形化管理软件，下载链接为：https://www.docker.com/products/docker-desktop/。建议不开启WSL2，否则可能与电脑其他软件存在冲突（除非电脑中已经使用了WSL2虚拟机，那么这里勾选开启）。
注：如软件安装空间不足，可以把安装路径指向一个新的路径：可以参考这里修改安装路径
用管理员权限打开CMD，然后输入mklink /j "C:\Program Files\Docker" "D:\Program Files\Docker"。这样，软件看似安装在原目录，实则安装在了"D:\Program Files\Docker"。当然也可修改为其他盘。
2.启动Docker服务
安装完Docker Desktop，运行启动它，界面如下所示。
看到左下角显示Engine running说明启动成功。
3.拉取镜像
3.1准备工作：检查磁盘剩余存储空间
首先需要检查电脑系统盘（C盘）空间剩余空间是否超过6GB，实际建议有10GB及以上。如果空间足够，可以跳转到3.2，如空间容器和镜像存储空间不足，旧版本Docker Desktop可以直接在软件中设置新的存储路径，但新版就不行了，下面介绍新版的用法。参考来源：修改存储路径。
1）列出待迁移数据
退出Docker Desktop软件，以防冲突。打开CMD，输入wsl --list -v，把所有相关的数据文件列出来，稍后需要挨个迁移。
此时，返回的信息是如上图所示，那么需要迁移的数据有：docker-desktop-data STOPPED 2，docker-desktop STOPPED 2。有的只出现一条，那么只要迁移这一个就好。接下来，以把数据迁移到D盘为例进行说明。
2）新建保存目录
在D盘新建目录用于保存迁移过去的数据，例如我后续希望相关数据都迁移到"D:\Program Files\Docker"，那么我就得新建这个目录，保证路径"D:\Program Files\Docker"存在。
3）导出数据
在CMD中输入：wsl --export docker-desktop-data "D:\Program Files\Docker\docker-desktop-data.tar"。如果有其它要导出，指令类似。例如我们还需要导出docker-desktop，那么运行完上一句，继续输入：wsl --export docker-desktop "D:\Program Files\Docker\docker-desktop.tar"。
4）注销WSL中原来的数据
在CMD中输入：wsl --unregister docker-desktop-data。如果有其它要注销，指令类似。例如我们还需要注销docker-desktop，那么运行完上一句，继续输入：wsl --unregister docker-desktop。
5）导入数据到新的存储路径
在CMD中输入：wsl --import docker-desktop-data "D:\Program Files\Docker\data" "D:\Program Files\Docker\docker-desktop-data.tar" --version 2。这里的"D:\Program Files\Docker\data"是新的存储路径，这个文件夹会自动创建。
若还需要迁移docker-desktop，运行完上一句，继续输入：wsl --import docker-desktop "D:\Program Files\Docker\data" "D:\Program Files\Docker\docker-desktop.tar" --version 2。
6）重启Docker Desktop
此时已经完成了容器文件的存储位置迁移。如果有问题，可以尝试重启电脑。如果正常迁移完成，可以删除导出的tar文件，即D:\Program Files\Docker\docker-desktop-data.tar。如需迁移到其他盘，也可参照此方式完成，只需要修改盘符即可。
3.2拉取镜像
Docker分为容器（Container）和镜像（Image），（有时还会额外有一类叫Dockerfile）。首先需要从云端获取镜像，类似于安装操作系统的镜像，这个镜像是和原版一模一样的。然后可以启动容器，容器可以由用户自主修改。
拉取镜像的命令如下：
docker pull xedu/xedu:v3s
打开电脑的命令行（CMD）窗口，输入上面的命令行。
这一步会拉取xedu的镜像文件到本地磁盘，因此务必保证您的电脑系统盘空间剩余空间超过5GB，实际建议有10GB及以上空间，便于后续训练使用。如果想要调整存储空间位置，可以参考上面空间不足的解决办法。刚开始拉取没有相应，可以等待一会儿，就会出现下面的拉取进度的界面。
等待拉取完成，所用时间取决于网速（大约30分钟-2小时之间），您也可以参考相关教程配置国内镜像源来加快拉取速度。如：这个办法。
4.启动docker容器（Container）
在CMD输入：
docker run -it -p 5000:5000 -p 8888:8888 --mount type=bind,source=D:/share,target=/xedu/share xedu/xedu:v3s，首次使用会询问是否绑定磁盘，选择Yes。运行成功界面如下：
接下来就可以用电脑访问 127.0.0.1:8888 访问jlab，通过 127.0.0.1:5000 访问easytrain。（电脑中的文件想要拷贝进docker，可以放到D盘share文件夹）。美中不足的是，这两个网址需要自行打开浏览器后输入。如果显示效果不佳，可能是浏览器不兼容，建议下载最新版的chrome浏览器。
可能用到的docker命令
查看现有的容器
  docker ps -a
暂停容器
  docker stop 34。
  假设使用ps查看到容器ID是1234567890，还有另一个容器ID是1243567890，我们在指定的时候，只要输入其中的任意一小段，可以区分开不同的容器即可，例如可以用34或者1234之类来区分这两个不同的容器。
再次启动容器
  docker start 34
进入容器的命令行窗口
  docker exec 34 -it bash
5.结束容器
在刚才的命令行窗口中，输入CTRL+C，再输入y，即可结束容器。
6.重启容器
已完成容器的安装，再次重启容器只需启动Docker服务，再完成5.启动容器的操作即可。
如何快速查看XEdu各模块库的版本
打开python终端，执行以下命令即可查看XEdu各模块库的版本。当前最新版本是0.1.21。
注：目前版本MMEdu仅支持CPU。
如何卸载XEdu各模块库
如果XEdu某模块库出现异常情况，可以尝试使用uninstall命令卸载，然后再使用install命令安装。参考代码：
$ pip uninstall MMEdu -y
$ pip uninstall BaseNN -y
$ pip uninstall BaseML -y

XEdu大事记
活动历史
2024年3月，2024全球开发者先锋大会（GDC）——OpenHydra主题工作坊
2024年1月，2023年全国青少年人工智能创新实践活动交流展示会
开发历史
2024年4月，XEduHub支持大模型和图像风格迁移
2024年1月，XEduHub支持自动驾驶工具
2023年11月，发布easy-xedu 0.0.1版（eastdl系列上线pip包）
2023年9月，启动XEdu-Hub模块的编写，发布XEdu-python 0.0.1版
2023年8月，启动信息科技版教学版一键安装包制作
2023年5月，启动BaseDeploy模块的编写。
2023年1月，启动全国新一代人工智能教师成长营活动，报名人数数千人；在OpenInnoLab上线XEdu专属容器。
2022年12月，启动BaseDT模块的编写。
2022年11月，在第十届中小学STEAM教育大会展示，开设一天的工作坊活动（8个活动），随后在温州大学开设浙江省AI教师培训活动。MMEdu加入模型转换模块。
2022年10月，编写Easy系列工具，实现无代码训练和推理。
2022年9月，在世界人工智能大会的智能教育论坛上正式发布。
2022年8月，上线MMEdu pip包，并整合在OpenInnoLab平台上。
2022年7月，发布MMEdu 0.7版。
2022年6月，发布MMEdu 0.6版，启动XEdu整体规划，增加了BaseNN和BaseML。
2022年5月，封装MMEdu一键安装包。
2022年4月，发布MMEdu 0.5版。
2022年3月，完成内测版，确定目录，规范路径；同步编写课程，设计AI实验。
2022年2月，确定语法风格。
2022年1月，工作启动，组建核心团队。
2021年11月，确定想法——将OpenMMLab“降维”，让中小学生能够使用。
媒体关注
2022年，中国信息教育杂志社特约记者吴俊杰博士访谈戴娟和谢作如。
文章链接：中小学人工智能教育需要怎么样的工具

XEdu的设计
XEdu的定位是什么？
XEdu的全名为OpenXLabEdu，是基于OpenXLab的教育版，也是为中小学AI教育设计的一套完整的学习工具。OpenXLab是上海人工智能实验室开源的AI工具集合。
XEdu核心工具为深度学习工具库XEduHub、计算机视觉库MMEdu，加上神经网络库BaseNN和传统机器学习库BaseML，后期规划中会增加OpenDILabEdu和OpenDataLabEdu等，覆盖实验室开源的所有人工智能工具，支持中小学可能涉及到AI技术所有领域。
如何用XEdu借助AI解决真实问题
揭秘XEdu
1.应用先行，逐层深入
XEdu的核心工具MMEdu内置SOTA模型，让学生把机器学习作为解决问题的有效工具，先应用，再逐步研究背后的原理。就如互联网，不是先讲ISO七层协议，而是先打开浏览器获取信息，打开EMail交流信息，再慢慢走向底层的协议。
XEdu的基础工具BaseDT，则是一个整合了常见数据处理工具的基础库。借助这个库，用一行代码即可完成数据的预处理，让AI应用的代码更加简洁。
2.代码最简，部署方便
将AI工具分解为“训练”和“部署”两种核心功能。无论是BaseML、BaseNN还是MMEdu，全部采用一致的语法完成训练、推理和转换、部署。
3.兼容并蓄，灵活扩展
虽然语法上做到最简，但是兼容原生工具的各种功能，如BaseNN和BaseML分别保留了Pytorch和Sklearn的功能，MMEdu则保留了OpenMMLab的各种参数，尤其是模型训练的所有常见参数，让学生在不同阶段都可以使用OpenXLab的系列工具进行学习。在不久的将来，用BaseNN可以搭建MMEdu的模型，多个工具形成一个强大的AI工具包，能支撑中小学绝大多数的AI学习。
了解XEdu的规划
1.深度学习工具库：XEduHub
XEduHub是一个集合了各种各样深度学习工具的模块，可以让用户高效地完成深度学习任务。
2.计算机视觉开发库：MMEdu
MMEdu全称为OpenMMLabEdu，是著名的计算机视觉开发工具OpenMMLab的教育版本。 
3.神经网络开发库：BaseNN
BaseNN是神经网络库，能够使用类似Keras的语法搭建神经网络模型。
4.传统机器学习开发库：BaseML
BaseML是传统机器学习库，类似Sklearn，使用了与MMEdu同样的语法。 
5.EasyDL系列无代码工具
一系列方便初学者的小工具，可以在无代码的情况下完成模型的训练、推理、转换和部署，甚至可以搭建一个WebAPI服务器，类似百度AI开放平台。
6.数据处理工具库：BaseDT
不同的模型对数据有特定的要求，比如LeNet-5是28×28，MobileNet是224×224。BaseDT集成了各种数据处理工具。
7.其他规划中的库
规划中的库还有OpenDILabEdu和OpenDataLabEdu，从名称可以看出源自上海人工智能实验室的各种工具。
XEdu的愿景
“接地气，望云端”，开源科创团队期望XEdu是一款适合中小学生入门，同时又能编写出可以“真正运行”的AI代码的人工智能开发工具，让学生能够通过完成各种AI实验，亲历从收集数据到训练深度学习模型的过程，并能够通过训练AI模型、部署智能信息系统的方式，解决生活中的真实问题。

XEdu的故事
从MMEdu到XEdu
XEdu的缘起来自MMEdu，而MMEdu的诞生有很多版本，但所有的版本都围绕着“中小学AI教育”展开。
版本一
上海人工智能实验室成立初期，智能中心负责人戴娟找上海交大谈国智班（实验室和交大共同培养的人工智能班）的相关事宜。他们不约而同关注到中小学的人工智能教育，都认为要在中小学推广人工智能教育，就需要更加接地气的AI开发工具。于是开始有意识地选择一些技术门槛较低，又比较有趣的AI工具，尝试降维后给中小学生使用。
经过几次迭代，他们最后选择了OpenMMLab进行降维。因为OpenMMLab是一个非常全面的计算机视觉的算法包，内置了很多SOTA 模型。
……
版本二
2020年，清华大学出版社的义务教育阶段信息技术教材开始修订，其中九年级分册要涉及人工智能。经过一番调研，几位主编发现小学教材可以用Mind+，高中教材绝大多数使用了Keras，那么初中呢？似乎也只能选择Keras。教材编写出来后，老师们都认为太难，代码中有些单词很难理解。
2022年，教材副主编谢作如老师（原温州中学，现温州科技高级中学）在世界人工智能大会见到戴娟，聊起中小学人工智能需要好的AI开发工具这一问题。戴娟说实验室有好多工具，只是不知道是否适合中小学，也不知道应该往哪一个方向优化。两人在AI教育上观点一致，只是时间来不及，于是约好下次来温州讨论。
很快地，戴娟将实验室的工具整理了一个列表，来温州向谢作如一一展示。谢作如则一下子看中了内置SOTA模型的OpenMMLab。他们很快就组建了一个名称为“开源科创”的开发团队，以贾彦灏、王博伦等实验室智能教育中心实习生为核心，开始了OpenMMLab的“降维”工作。
MMEdu的正式启动时间是2022年1月。陆雅楠和邱奕盛的加入让小团队的力量大增。这个小团队取名为开源科创团队，分为算法和教研两个小组。开源科创团队深度对比了Keras、FastAI、ModelArts等的AI开发工具，总结了深度学习的一般流程，认为AI模型训练和AI模型推理（应用开发）工作应该分离，而AI模型训练应该是公式化的操作，可以设计一套非常简洁的代码，以降低技术门槛。
MMEdu很快就推出了第一版，邀请了国内的骨干教师进行内部测试，得到大家的好评。其中山东的于方军老师还提了很多建议。随着开发的深入，一些新的需求也逐步明晰起来。因为MMEdu面向计算机视觉，内置的都是视觉方向的SOTA模型，无法搭建一些简单的经典网络，如全连接神经网络（BP神经网络），再加上当前教材中又不可避免要讲经典机器学习，于是又增加了BaseNN和BaseML。这些工具合并起来，取了一个共同的名称——XEdu（全称为OpenXLab-Edu），和实验室的XLab对应。
2023年9月，XEdu迎来了新伙伴——XEduhub。
为什么要开发XEdu
中小学的AI教育需要低门槛的框架或者工具。受限于认知水平，中小学生很难去理解AI的底层，尤其是数学原理。而当前的AI教育往往“满足于”给学生介绍AI发展史、专家系统、知识图谱和一些经典的机器学习原理，学生无法用学到的知识去解决一些真实问题。有人戏称这样的AI教育不过是在教屠龙技——因为世上已经无龙可屠，那么学了跟没学一样。
在2022年之前，中小学的AI课程中如果涉及到用代码训练AI模型，一般都选择了keras。虽然Keras有着种种不尽人意的地方，却找不到更好的替代品——至少比TensorFlow已经简单多了。但是Keras最大的问题在于代码过于底层，如搭建神经网络需要一层一层搭建，连搭建LeNet（一个最经典最基础的卷积神经网络模型）都要写好多代码，实际上学生只能照着教学或者范例抄一遍，并不能真正理解。那么，这样抄一遍的意义又在哪里？
经过多次的研讨，开源科创团队对当前中小学的AI教育进行了总结，认为其存在如下问题：
1）AI教育涉及的内容离应用太遥远，解决不了真实问题。简而言之，学了跟没学一样。
2）有些AI工具虽然能解决问题，却又封装过度，如OpenCV和MediaPipe，只能算AI应用工具，不算AI开发工具。 
3）一本教材往往要涉及多个工具，导致门槛太高。如物体检测的Yolov3，常见代码基于DarkNet。虽然有PyTorch的代码，GitHub上提供的是一个完整的项目，大部分教师不知道如何使用；再如图片风格化（学习迁移，对抗网络） ，老师们只能体验一下现成的应用。
XEdu的定位是面向中小学AI教育的开发和学习工具。
杂志专稿：中小学需要怎样的AI学习工具
20222年春，北京师范大学吴俊杰博士受《中国信息技术教育》杂志社委托，以“中小学 AI 教育需要怎样的工具“为主题，邀请戴娟和谢作如做了一期对话。

了解开发和维护团队
1. 项目策划
1）戴娟 
硕士（人工智能方向），上海人工智能实验室智能教育中心主任，项目总负责。 
2）谢作如 
高中信息技术正高级教师，上海人工智能实验室智能教育中心科创主管，浙江省特级教师，负责具体研发进度和课程开发。 
3）张崇珍 
硕士（计算机视觉方向），负责项目的外部沟通和协调。
4） ……
2. 算法团队
1）王博伦（上海人工智能实验室，上海交通大学）
2）贾彦灏（中国科学院大学）
3）张格致（上海交通大学）
4）梁伊雯（同济大学）
5）高剑雄（上海复旦大学）
6）丛培珊（上海科技大学）
7）姜燕炜（上海交通大学）
8）张卉婧（上海复旦大学）
9）徐泽庭（华东师范大学）
……
3. 课程团队
1）陆雅楠（上海人工智能实验室，上海师范大学）
2）邱奕盛 （华东师范大学）
3）高毓甜 （华东师范大学）
4）程龙恺（中国石油大学（华东））
5）李子健（华东师范大学）
6）胡君豪（湖北工业大学）
7）周子皓（华东师范大学）
8）胡潇桓 （美国纽约大学）
……
4. 测试团队
1）郑祥（温州市第四中学）
2）张敬云（江苏省镇江市实验高级中学）
3）……
期待您的参与！

版本更新记录
1. 正式版
发布时间：2022年9月
开发计划
1.实现以pip方式安装。
2.分MMEdu、BaseML、BaseNN三个功能模块。
3.工具持续迭代，增加了模型部署库BaseDeploy和数据处理库BaseDT。
正式版更新记录
1）MMEdu
V0.1.23 20231207
模型转换生成的示例代码文件由basedeploy修正为xedu-python。
ssd_lite载入数据集完善，配置文件完善。
V0.1.20 20230704
cls的sota()函数完善，无需声明。
V0.1.15 20230605
对模型生成示例代码和载入onnx权重信息做了拓展和调整。
V0.1.14 20230517
优化批量推理时show_result的判断逻辑，避免大量占用内存导致的内核中断。
V0.1.9 20230423
合并git与飞书中的最新版本。
更新cls和det转换生成内容以适配最新XEdu库。
消除生成onnx权重大段warning。
类别压入生成的权重。
train()函数返回log。
权重文件中保存版本号。
V0.1.8 20230316
pth存储信息完善。
pth_info函数展示权重文件相关信息。
V0.1.7 20230313
更新cls和det模型转换后生成的py文件内容。
V0.1.6 20230302
cls和det的推理和转化函数中去除了class_path这一参数，类别信息从pth中获得。
修复SSD_Lite类名传递不正确的问题。
V0.1.5 20230203
det修正infer和convert中类别数量的问题。
det模型训练时会自动保存best_map的权重。
det 规范化数据集文件夹名称。
修复SSD_Lite类名传递不正确的问题。
V0.1.4 20230106
cls+det同时增加可选batch_size功能。
det补充SSD和yolov3。
det输出格式由xywh修正为x1y1x2y2。
V0.1.3 20221222
det增加模型转化功能。
cls+det更新模型转化功能，参数调整，会额外输出config文件。
V0.1.2 20221215
cls：
cls检查数据集中图片shape，指出损坏图片。检查图片出现损坏时，抛出错误码The image file xxx is damaged。
数据集如缺少txt，自动生成。
case1：数据集缺少classes.txt, val.txt ，会自动生成并提示, eg，“生成val.txt”。
case2：如缺少test_set，可正常训练，但不会生成test.txt 。（不影响正常功能）
case3：如缺少val_set，可训练，但不能验证，即train函数中validate参数不能为True。（功能受损，看不到准确率，但还是可以训练出模型）。
其他：
允许数据集中出现其他类别的文件，eg,csv；
数据集中test_set可以不按照类别存放。
检查写权限，确定写到哪里
innolab上数据集没有读写权限，则将txt生成至项目内，文件夹名为dataset_txt，内含classes.txt，val.txt。(若有读写权限则生成至数据集路径内）
​   4.加入模型转换convert()函数，pth转onnx。
det：
det增加支持PIL和np array 输入功能。图片形式可以通过PIL和np数组进行输入，PIL和数组列表也支持输入。
参考cls，det增加相关错误码。
V0.1.1 20221118
​   支持读入pil，np格式数据。
V0.1.0 20221111
train和infer的device=cuda检查torch.cuda.is_available()，device=cpu当cuda可用时提示可以使用cuda加速。
文件夹推理LeNet无误。
fast_infer支持LeNet。
V0.1.0rc2 20221111
​   同V0.0.9，少依赖版本。
V0.0.9 20221104
检测模块训练函数支持device参数。
load_checkpoint()参数顺序更换。将checkpoint前置（第一个），device后置，可以只输入路径，而省略 "checkpoint="。
fast_infer错误反馈，补充错误情况，当fast_infer之前未使用load_checkpoint载入ckpt时会提示错误码305。
MMEdu.__ path __ 可正常返回环境中包所在地址。
修复lenet 文件夹推理问题。
V0.0.1rc2 20221104
​   同V0.0.9，少依赖版本。
V0.0.8 20221102
加入错误反馈机制。
增加命令行字符画和简介。
提示目前支持的主干网络。
支持推理opencv、PIL读入的图片。
模型声明时允许读入配置文件，而不仅是模型名。
V0.0.1rc1 20221102
​   同V0.0.8，少依赖版本。
2）BaseML
V0.1.1 20240313
新增valid中三个聚类评价指标。
V0.1.0 20240306
新增load_tab_data载入表格数据集功能。
新增valid函数用于验证评估模型性能。
线性回归可获得斜率和截距。
新增参数设定方式。
metricplot画图标题修改。
V0.0.6 20230217
与MMEdu的错误提示码风格进行了统一，并在此基础上进行了BaseML部分的补充。
所有库类代码应用了PEP8代码规范，使得代码结构与语句更加美观。
V0.0.5 20230210
完成模型可视化和评测指标可视化两个库。目前只有4种算法支持可视化，大部分模型支持评测指标可视化，少部分不支持。
引入yellowbrick库，用于评测指标可视化。
修改了load_dataset函数，cls和reg默认split=True, 即划分为训练和测试集， 聚类和降维默认不划分。
加入了警告（蓝色字体）和报错（红色字体），但待与MMEdu的风格统一。
V0.0.4 20221121
​   按照cls中的分类算法，给reg中的算法名进行了更改与添加，目前的回归算法有：['LinearRegression', 'CART', 'RandomForest',       'Polynomial', 'Lasso', 'Ridge', 'SVM', 'AdaBoost', 'MLP']。
V0.0.3 20221115
​   把 from BaseML import Classification  调用为Classification.cls  改成了 from BaseML import Classification as cls  调用为 cls(algorithm= ...)。
V0.0.2 20221110
给每个类增加了docstring类型的注释，可以使用cls.__doc__查看拥有的算法以及类注释。
更改了load_dataset函数的初始默认值，默认shuffle, 不展示前5条数据，不划分数据集，不进行数据归一化。
添加了反归一化函数，可以将归一化后的数据转换为原数据，在base.reverse_scale函数中。
V0.0.1 20221110
load_dataset中设置了X和y的默认列，如果没有标明x_column和y_column，默认采用输入的所有列。但输入的是txt或csv格式的话，一定要标注出列号，否则报错。
inference()中加了参数verbose，默认值为True，表示会输出训练过程中的过程数据，False则不会。
train()中设置了参数validate（默认为True），表示会将输入的训练集划分为训练集和验证集，并输出验证集下的模型准确率。
添加了图片读取处理模块ImageLoader，具体使用方式查看文件中的注释以及demo实现。
对于加载数据集，添加了几个bool标记：shuffle, show, split, scale，分别表示是否打乱数据集、是否展示5条数据、是否划分数据集、是否对训练数据进行归一化。
每个模型的初始化增加了参数字典方法，便于更高级的模型调参。
3）BaseNN
V0.2.9 20240311
load_img_data函数transform方式优化。
V0.2.6 20240108
模型转化生成的推理代码调整。
增加载入数据时num_wokers控制，增加模型转化时中间版本、算子集版本控制。
新增搭建残差网络功能。
V0.2.3 20231207
basenn模型转换生成对应的xedu-python推理代码。
V0.2.1 20231013
支持basenn导出的pth文件转化为onnx。
V0.1.8 20230710
numpy数组推理优化。
V0.1.7 20230706
numpy数组推理优化。
V0.1.6 20230531
训练速度优化，dataloader多线程读取设置。
V0.1.5 20230529
basenn层名兼容大小写，推荐全部采用小写。
图片文件夹、特征csv格式数据集设计并实现。
V0.0.7 20230322
继续训练，特征可视化适配新的pth文件格式。
V0.0.6 20230317
保存模型文件由pkl统一为pth，加入pth_info()。
加入RNN部分。
V0.0.5 20221215
可视化特征，只有传统意义上的层才计数，relu，reshape，softmax不计数;且当输入为二维图像时，展示可视化的图像，输入为一维数据时，生成txt保存每层之后的输出。
加入随机数种子，确保当指定种子后，反复训练可以得到完全一致的结果。
可选损失函数，可选评价指标。
V0.0.4 20221202
​   参数控制可视化，一整张图or一系列图。
V0.0.3 20221116
​   增加提取特征，可视化特征功能。
4）BaseDT
V0.1.3 20240229
split_tab_dataset()新增参数column_name,可传入列表,自定义列名。
V0.1.2 20230914
修正了FasterRCNN模型输入图像尺寸的问题。
V0.1.1 20230626
修复BaseDT中plot模块在自定义载入时绘图通道顺序显示的错误。
修改plot对分类问题显示时重复出现pred_label。
V0.1.0 20230621
修复plot在绘图时信息未载入而引发报错的问题。
V0.0.9 20230620
修复了plot使用show时函数冲突问题。
增加了MMPose绘图所需的模块。
修复了get_img时调用了show函数导致会使用plt进行绘制的问题。
util模块增加MMPose SIMCC格式推理前后处理的内容（之后得考虑将其迁移至data模块中）。
V0.0.8 20230616
画图功能完善。
V0.0.7 20230609
划分csv数据集加入归一化功能。
V0.0.6 20230607
加入划分csv数据集功能。
取消jieba安装依赖，仅在函数内部引用。
basedeploy相关的功能更新。
V0.0.4 20230426
log_plot接入train时日志导出。
类名导出函数重命名为get_label。
修复imshow_det_bboxes、map_orig_coords函数的一些漏洞。
V0.0.1 20230209
​   首次上源。
5）XEdu一键安装包
V1.6.7 20231129
​   删除PyQt5库。
​   Thonny版本调整为稳定的3.3.13。
​   增加xedu-hub的workflow功能。
​   增加新版Easy系列（easy-xedu）。
​   优化文件目录。
​   同时发布XEdu信息科技教学版1.3a版本。
V1.6.6 20231116
​   添加新版Easy系列测试版本，大约70人内测。
V1.6.5 20231020
​   更新BaseNN库，支持onnx模型转换。
V1.6.4 20231010
​   更新BaseNN库，支持回归任务（model = nn('reg')）。
​   更新XEdu-python库，支持更多推理任务工作流（workflow）。
V1.6.3 20230916
​   修正bug。
V1.6.2 20230912
​   修正bug。
V1.6 20230901
​   重构opencv-python库环境。
​   支持bug解决脚本（解决绝大多数问题）。
​   支持jupyter notebook中文。
​   升级库版本MMEdu0.1.21，BaseNN0.2.0，BaseML0.0.6、BaseDT0.1.1、BaseDeploy0.0.4。
​   支持openxlab下载（https://download.openxlab.org.cn/models/yikshing/bash/weight/x16）
V1.5.4 20230811
​   升级库版本。
​   支持cmd终端一键启动。
​   支持jupyter notebook中文。
V1.5.2 20230613
​   升级库版本。
V1.4.6 20230529
​   解决BaseNN推理缓慢的问题。
V1.4.5 20230529
​   升级BaseNN语法；
​   修复pip安装失败的问题；
​   优化easy系列功能。
V1.4 20230516
​   支持模块：MMEdu0.1.13（支持cls和det），BaseNN0.0.9，BaseML0.0.6（支持cls、reg和clt）、BaseDT0.0.5（支持通用数据处理）
​   内置编辑器：jupyter、pyzo、三个可视化工具（EasyTrain EasyInference EasyAPI）
​   升级支持模型转换onnx、推理和部署语法精简，不再需要class_path。BaseML支持绘图。
V1.3 20230416
​   支持模块：MMEdu0.1.8（支持cls和det），BaseNN0.0.9，BaseML0.0.6（支持cls、reg和clt）、BaseDT0.0.2（支持通用数据处理）
​   内置编辑器：jupyter、pyzo、三个可视化工具（EasyTrain EasyInference EasyAPI）
V1.2 20230110
​   支持模块：MMEdu0.1.4（支持 cls 和 det），BaseNN0.0.5，BaseML0.0.3（支持 cls、reg 和 clt） 
​   内置编辑器：jupyter、pyzo、三个可视化工具（EasyTrain EasyInference EasyAPI） 
V1.1 20221220
​   支持模块：MMEdu0.1.2（支持cls和det），BaseNN0.0.5，BaseML0.0.3（支持cls、reg和clt）
​   内置编辑器：jupyter、pyzo、三个可视化工具（EasyTrain、EasyInference和EasyAPI）
6）BaseDeploy
V0.0.3 20230626
新增demo实例文件夹，内置lenet的onnx模型。
预测结果保留未润色后的形式，并可使用print_result对结果进行润色。
7）XEdu-python
V0.1.5 20240513
utils新增可视化相似度矩阵和可视化类别概率分布功能。
V0.1.3 20240320
对BaseML任务的输入数据格式提示。
V0.1.1 20240131
初步加入错误码体系。
人脸检测新增可调参数。
V0.0.8 20231219
增加文本嵌入和图像嵌入任务。
V0.0.7 20231120
增加文本问答任务。
增加驾驶感知任务。
V0.0.5 20231103
增加风格迁移任务。
增加图像分类任务。
V0.0.3 20231013
增加人手检测任务。
优化ocr中show=True时的显示问题。
支持basenn导出的onnx模型。
V0.0.2 20231008
增加人脸检测任务、ocr任务。
优化参数。
支持mmedu导出的onnx模型。
V0.0.1 20230928
实现五个姿态估计任务（人体*2、手势、人脸、全身）和两个目标检测任务（人体，coco80类别）的简明工作流程。
2. 测试版
XEdu 0.1.0版
发布时间：2022.11
版本说明：优化MMEdu、BaseML、BaseNN等模块，增加EasyAPI.bat、EasyInference.bat、EasyTrain.bat三个可视化工具，更新所有示例代码。
MMEdu pip-0.0.1版
发布时间：2022.8
版本说明：发布内测版pip包。
XEdu 0.0.1版
发布时间：2022.6
版本说明：重构目录结构，建立MMEdu和BaseML两大模块。
0.7版
发布时间：2022.6
版本说明：优化0.5版两个模块，新增自定义网络（BaseNN）模块。
0.5版
发布时间：2022.4
版本说明：整合图像分类（cls）、物体检测（det）两个核心模块，内置Pyzo、Jupyter，实现一键部署。

